import torch
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
import torchvision.transforms as transforms

COLORS = [
    [1.0, 0.0, 0.0],    # fully-ripe (red) - ì§„í•œ ë¹¨ê°•
    [1.0, 0.647, 0.0],  # semi-ripe (orange) - ì§„í•œ ì£¼í™©
    [0.0, 0.5, 0.0],    # unripe (green) - ì§„í•œ ì´ˆë¡
]

def box_cxcywh_to_xyxy(x):
    x_c, y_c, w, h = x.unbind(1)
    b = [(x_c - 0.5 * w), (y_c - 0.5 * h), (x_c + 0.5 * w), (y_c + 0.5 * h)]
    return torch.stack(b, dim=1)

def rescale_bboxes(out_bbox, size):
    img_w, img_h = size
    b = box_cxcywh_to_xyxy(out_bbox)
    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)
    return b

def plot_results(pil_img, prob, boxes, id2label):
    plt.figure(figsize=(16, 10))
    plt.imshow(pil_img)
    ax = plt.gca()
    
    for p, (xmin, ymin, xmax, ymax) in zip(prob, boxes.tolist()):
        cl = p.argmax()
        color = COLORS[cl % len(COLORS)]
        ax.add_patch(plt.Rectangle(
            (xmin, ymin), xmax - xmin, ymax - ymin,
            fill=False, color=color, linewidth=3
        ))
        text = f'{id2label[int(cl.item())]}: {p[cl]:0.2f}'
        ax.text(xmin, ymin - 5, text, fontsize=12, color='white',
                bbox=dict(facecolor=color, alpha=0.8, pad=2))
    
    plt.axis('off')
    plt.tight_layout()
    plt.show()

def visualize_predictions(image, outputs, id2label, threshold=0.7):
    probas = outputs.logits.softmax(-1)[0, :, :-1]
    keep = probas.max(-1).values > threshold
    bboxes_scaled = rescale_bboxes(outputs.pred_boxes[0, keep].cpu(), image.size)
    plot_results(image, probas[keep], bboxes_scaled, id2label)


def save_detection_images(predictions, targets, images, output_dir, class_names, id2label, max_images=50):
    """ê°œë³„ ì˜ˆì¸¡ ì´ë¯¸ì§€ ì €ì¥"""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    for i, (pred, target, image) in enumerate(zip(predictions, targets, images)):
        if i >= max_images:
            break
            
        # ì´ë¯¸ì§€ê°€ tensorì¸ ê²½ìš° PILë¡œ ë³€í™˜
        if torch.is_tensor(image):
            image = transforms.ToPILImage()(image)
        
        # ì˜ˆì¸¡ ê²°ê³¼ ê·¸ë¦¬ê¸°
        draw = ImageDraw.Draw(image)
        
        # Ground truth (ì´ˆë¡ìƒ‰)
        gt_boxes = target["boxes"]
        gt_labels = target["labels"]
        
        for box, label in zip(gt_boxes, gt_labels):
            x1, y1, x2, y2 = box_cxcywh_to_xyxy_pil(box, image.size)
            draw.rectangle([x1, y1, x2, y2], outline="green", width=3)
            draw.text((x1, y1-15), f"GT: {id2label[label.item()]}", fill="green")
        
        # Predictions (ë¹¨ê°„ìƒ‰)
        pred_boxes = pred["boxes"]
        pred_labels = pred["labels"]
        pred_scores = pred["scores"]
        
        for box, label, score in zip(pred_boxes, pred_labels, pred_scores):
            x1, y1, x2, y2 = box_cxcywh_to_xyxy_pil(box, image.size)
            draw.rectangle([x1, y1, x2, y2], outline="red", width=2)
            draw.text((x1, y2+5), f"Pred: {id2label[label.item()]} ({score:.2f})", fill="red")
        
        # ì €ì¥
        image.save(output_dir / f"prediction_{i:04d}.jpg")
    
    print(f"Saved {min(len(predictions), max_images)} prediction images to {output_dir}")


def box_cxcywh_to_xyxy_pil(box, image_size):
    """CXCYWHë¥¼ PIL ì´ë¯¸ì§€ìš© XYXYë¡œ ë³€í™˜"""
    img_w, img_h = image_size
    cx, cy, w, h = box
    
    # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
    cx = cx * img_w
    cy = cy * img_h
    w = w * img_w
    h = h * img_h
    
    x1 = cx - w/2
    y1 = cy - h/2
    x2 = cx + w/2
    y2 = cy + h/2
    
    return int(x1), int(y1), int(x2), int(y2)


def plot_confusion_matrix(cm, class_names, output_path, title="Confusion Matrix"):
    """Confusion matrix í”Œë¡¯ ë° ì €ì¥"""
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        cm, 
        annot=True, 
        fmt='d', 
        cmap='Blues',
        xticklabels=class_names,
        yticklabels=class_names
    )
    plt.title(title)
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    
    if output_path:
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"Confusion matrix saved to: {output_path}")
    
    plt.close()


def plot_class_metrics(class_stats, class_names, output_dir):
    """í´ë˜ìŠ¤ë³„ ë©”íŠ¸ë¦­ ì‹œê°í™”"""
    output_dir = Path(output_dir)
    
    metrics = ['precision', 'recall', 'f1']
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    for i, metric in enumerate(metrics):
        values = class_stats[f'class_{metric}']
        
        bars = axes[i].bar(class_names, values, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
        axes[i].set_title(f'Class-wise {metric.capitalize()}')
        axes[i].set_ylabel(metric.capitalize())
        axes[i].set_ylim(0, 1)
        
        # ê°’ í‘œì‹œ
        for bar, value in zip(bars, values):
            axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                        f'{value:.3f}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig(output_dir / "class_metrics.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"Class metrics plot saved to: {output_dir / 'class_metrics.png'}")


def create_evaluation_report(results, output_path):
    """í‰ê°€ ê²°ê³¼ HTML ë¦¬í¬íŠ¸ ìƒì„±"""
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Evaluation Report</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 40px; }}
            .header {{ background-color: #f0f0f0; padding: 20px; border-radius: 5px; }}
            .metric {{ margin: 10px 0; }}
            .class-table {{ border-collapse: collapse; width: 100%; }}
            .class-table th, .class-table td {{ border: 1px solid #ddd; padding: 8px; text-align: center; }}
            .class-table th {{ background-color: #f2f2f2; }}
        </style>
    </head>
    <body>
        <div class="header">
            <h1>Model Evaluation Report</h1>
            <p><strong>Timestamp:</strong> {results['evaluation_info']['timestamp']}</p>
            <p><strong>Checkpoint:</strong> {results['evaluation_info']['checkpoint']}</p>
            <p><strong>Split:</strong> {results['evaluation_info']['split']}</p>
        </div>
        
        <h2>Detection Metrics</h2>
        <div class="metric">mAP@0.5: {results['detection_metrics']['map_50']:.4f}</div>
        <div class="metric">mAP@0.5:0.95: {results['detection_metrics']['map']:.4f}</div>
        
        <h2>Overall Statistics</h2>
        <div class="metric">Precision: {results['detailed_statistics']['total_statistics']['overall_precision']:.4f}</div>
        <div class="metric">Recall: {results['detailed_statistics']['total_statistics']['overall_recall']:.4f}</div>
        <div class="metric">F1-Score: {results['detailed_statistics']['total_statistics']['overall_f1']:.4f}</div>
        
        <!-- ì¶”ê°€ ë‚´ìš©ë“¤... -->
    </body>
    </html>
    """
    
    with open(output_path, 'w') as f:
        f.write(html_content)
    
    print(f"HTML report saved to: {output_path}")


# =============================================================================
# ê³µí†µ ì‹œê°í™” í•¨ìˆ˜ (Test/Inferenceìš©)
# =============================================================================

def get_model_color(model_name):
    """ëª¨ë¸ë³„ ìƒ‰ìƒ ë°˜í™˜"""
    model_colors = {
        'yolov11': (255, 165, 0),  # ì£¼í™©ìƒ‰
        'yolov12': (255, 255, 0),  # ë…¸ë€ìƒ‰
        'detr': (128, 0, 128),     # ë³´ë¼ìƒ‰
        'grounding dino': (139, 69, 19),  # ê°ˆìƒ‰
    }
    model_name_lower = model_name.lower()
    return model_colors.get(model_name_lower, (255, 255, 255))  # ê¸°ë³¸ê°’: í°ìƒ‰


def get_class_colors(num_classes):
    """í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ë°˜í™˜ (COLORS ìƒìˆ˜ ì‚¬ìš©)"""
    # COLORS ìƒìˆ˜ ì‚¬ìš© (0-1 ë²”ìœ„ë¥¼ 0-255ë¡œ ë³€í™˜)
    colors = {}
    for i in range(num_classes):
        if i < len(COLORS):
            # COLORSëŠ” 0-1 ë²”ìœ„ì´ë¯€ë¡œ 0-255ë¡œ ë³€í™˜
            colors[i] = tuple(int(c * 255) for c in COLORS[i])
        else:
            # ì¶”ê°€ í´ë˜ìŠ¤ëŠ” ìƒ‰ìƒ íŒ”ë ˆíŠ¸ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            import colorsys
            hue = i / max(num_classes, 1)
            rgb = colorsys.hsv_to_rgb(hue, 0.8, 0.9)
            colors[i] = tuple(int(c * 255) for c in rgb)
    return colors


def save_visualization_images(
    model, 
    dataset, 
    output_dir,
    config,
    show_gt=False,
    box_color_mode='class',
    confidence_threshold=0.5,
    split='test',
    max_images=None,
    show_labels=False
):
    """
    ê³µí†µ ì‹œê°í™” í•¨ìˆ˜ - ëª¨ë“  ëª¨ë¸ì—ì„œ ì‚¬ìš©
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸
        dataset: ë°ì´í„°ì…‹
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (Path ê°ì²´)
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        show_gt: GT í‘œì‹œ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
        box_color_mode: 'class' (í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ) ë˜ëŠ” 'model' (ëª¨ë¸ë³„ ìƒ‰ìƒ)
        confidence_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
        split: ë°ì´í„°ì…‹ split ì´ë¦„
        max_images: ìµœëŒ€ ì €ì¥ ì´ë¯¸ì§€ ìˆ˜ (Noneì´ë©´ ì „ì²´)
        show_labels: í´ë˜ìŠ¤ ë¼ë²¨ í…ìŠ¤íŠ¸ í‘œì‹œ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
    """
    if model is None or dataset is None:
        return
    
    # ì¸í¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    inference_dir = Path(output_dir) / "inference_images"
    inference_dir.mkdir(parents=True, exist_ok=True)
    
    device = next(model.parameters()).device
    model.eval()
    
    saved_count = 0
    class_names = config['data']['class_names']
    model_name = config['model']['arch_name']
    
    # max_images ì²˜ë¦¬
    if max_images is None:
        max_images = len(dataset) if dataset else 0
    
    total_images = min(len(dataset) if dataset else 0, max_images)
    
    # ìƒ‰ìƒ ì„¤ì •
    if box_color_mode == 'model':
        # ëª¨ë¸ë³„ ë‹¨ì¼ ìƒ‰ìƒ
        model_color = get_model_color(model_name)
        box_colors = {i: model_color for i in range(len(class_names))}
    else:
        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ (ê¸°ë³¸)
        box_colors = get_class_colors(len(class_names))
    
    print(f"Saving inference images to: {inference_dir}")
    print(f"Total images to process: {total_images}")
    print(f"Box color mode: {box_color_mode}")
    print(f"Show GT: {show_gt}")
    print(f"Show labels: {show_labels}")
    
    # íŒŒì¼ëª… ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ê¸° ìœ„í•œ ì¸ë±ìŠ¤ ë§¤í•‘ ìƒì„±
    # COCO ë°ì´í„°ì…‹ì—ì„œ ì´ë¯¸ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    sorted_indices = None
    image_id_to_filename = {}
    
    if hasattr(dataset, 'coco') and hasattr(dataset, 'ids'):
        coco = dataset.coco
        # ì´ë¯¸ì§€ IDì™€ íŒŒì¼ëª… ë§¤í•‘
        for img_id in dataset.ids:
            img_info = coco.loadImgs(img_id)[0]
            image_id_to_filename[img_id] = img_info['file_name']
        
        # íŒŒì¼ëª…ìœ¼ë¡œ ì •ë ¬ëœ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        sorted_indices = sorted(
            range(len(dataset.ids)),
            key=lambda idx: image_id_to_filename[dataset.ids[idx]]
        )
        print(f"Images will be saved in filename order (sorted by {len(sorted_indices)} filenames)")
    else:
        # COCO ë°ì´í„°ì…‹ì´ ì•„ë‹Œ ê²½ìš° ê¸°ì¡´ ìˆœì„œ ìœ ì§€
        sorted_indices = list(range(len(dataset)))
        print(f"Using dataset index order (COCO dataset not detected)")
    
    with torch.no_grad():
        for save_idx, dataset_idx in enumerate(sorted_indices[:total_images]):
            # ë°ì´í„°ì…‹ì—ì„œ ì´ë¯¸ì§€ì™€ íƒ€ê²Ÿ ê°€ì ¸ì˜¤ê¸°
            sample = dataset[dataset_idx]
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            if isinstance(sample, dict):
                image_tensor = sample['pixel_values']
                target = sample.get('labels') if show_gt else None
            else:
                image_tensor, target = sample if show_gt else (sample[0], None)
            
            # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            if image_tensor.dim() == 3:
                image_tensor = image_tensor.unsqueeze(0)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            image_tensor = image_tensor.to(device)
            outputs = model(image_tensor)
            
            # ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬ (DETR í˜•ì‹)
            probs = outputs.logits.softmax(-1)[0, :, :-1]
            scores, pred_labels = probs.max(-1)
            pred_boxes = outputs.pred_boxes[0]
            
            # ì„ê³„ê°’ ì ìš©
            keep = scores > confidence_threshold
            pred_boxes_filtered = pred_boxes[keep]
            pred_scores_filtered = scores[keep]
            pred_labels_filtered = pred_labels[keep]
            
            # ì´ë¯¸ì§€ë¥¼ PILë¡œ ë³€í™˜
            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
            
            image_denorm = image_tensor[0].cpu() * std + mean
            image_denorm = torch.clamp(image_denorm, 0, 1)
            
            to_pil = transforms.ToPILImage()
            pil_image = to_pil(image_denorm)
            
            img_w, img_h = pil_image.size
            draw = ImageDraw.Draw(pil_image)
            
            try:
                font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 16)
            except:
                font = ImageFont.load_default()
            
            # Ground Truth ê·¸ë¦¬ê¸° (ì˜µì…˜ì— ë”°ë¼)
            if show_gt and target is not None:
                gt_boxes = target.get('boxes', [])
                gt_labels = target.get('class_labels', [])
                
                if len(gt_boxes) > 0:
                    for box, label in zip(gt_boxes, gt_labels):
                        cx, cy, w, h = box
                        x1 = (cx - w/2) * img_w
                        y1 = (cy - h/2) * img_h
                        x2 = (cx + w/2) * img_w
                        y2 = (cy + h/2) * img_h
                        
                        draw.rectangle([x1, y1, x2, y2], outline="blue", width=4)
                        
                        if show_labels and label.item() < len(class_names):
                            text = f"GT: {class_names[label.item()]}"
                            draw.text((x1, y1-20), text, fill="blue", font=font)
            
            # Predictions ê·¸ë¦¬ê¸°
            for box, label, score in zip(pred_boxes_filtered, pred_labels_filtered, pred_scores_filtered):
                cx, cy, w, h = box
                x1 = (cx - w/2) * img_w
                y1 = (cy - h/2) * img_h
                x2 = (cx + w/2) * img_w
                y2 = (cy + h/2) * img_h
                
                color = box_colors.get(label.item(), (255, 255, 255))
                
                draw.rectangle([x1, y1, x2, y2], outline=color, width=4)
                
                if show_labels and label.item() < len(class_names):
                    text = f"{class_names[label.item()]}: {score:.2f}"
                    bbox = draw.textbbox((x1, y2+5), text, font=font)
                    draw.rectangle(bbox, fill=color)
                    draw.text((x1, y2+5), text, fill="white", font=font)
            
            # ì´ë¯¸ì§€ ì €ì¥ - íŒŒì¼ëª… ìˆœì„œëŒ€ë¡œ ì €ì¥
            if hasattr(dataset, 'coco') and hasattr(dataset, 'ids') and dataset_idx < len(dataset.ids):
                # COCO ë°ì´í„°ì…‹ì¸ ê²½ìš° ì›ë³¸ íŒŒì¼ëª… ì‚¬ìš©
                image_id = dataset.ids[dataset_idx]
                if image_id in image_id_to_filename:
                    original_filename = Path(image_id_to_filename[image_id]).stem
                    filename = f"inference_{original_filename}_{split}.jpg"
                else:
                    filename = f"inference_{save_idx:04d}_{split}.jpg"
            else:
                # COCO ë°ì´í„°ì…‹ì´ ì•„ë‹Œ ê²½ìš° ì¸ë±ìŠ¤ ì‚¬ìš©
                filename = f"inference_{save_idx:04d}_{split}.jpg"
            
            save_path = inference_dir / filename
            pil_image.save(save_path, quality=95)
            
            saved_count += 1
            
            if saved_count % 10 == 0:
                print(f"  Saved {saved_count}/{total_images} images...")
    
    print(f"âœ… Saved {saved_count} inference images to: {inference_dir}")
    
    # ë²”ë¡€ ì´ë¯¸ì§€ ìƒì„±
    create_legend_image(inference_dir, class_names, box_colors, show_gt)
    
    return inference_dir


def create_legend_image(inference_dir, class_names, box_colors, model_name=None, show_gt=False):
    """ë²”ë¡€ ì´ë¯¸ì§€ ìƒì„±"""
    legend_width = 400
    legend_height = 200 + len(class_names) * 30
    legend_img = Image.new('RGB', (legend_width, legend_height), 'white')
    draw = ImageDraw.Draw(legend_img)
    
    try:
        font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 16)
        title_font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 20)
    except:
        font = ImageFont.load_default()
        title_font = ImageFont.load_default()
    
    draw.text((20, 20), "Detection Legend", fill="black", font=title_font)
    
    y_offset = 60
    if show_gt:
        draw.rectangle([20, y_offset, 40, y_offset+20], outline="blue", width=3)
        draw.text((50, y_offset+5), "Ground Truth", fill="blue", font=font)
        y_offset += 30
    
    for i, class_name in enumerate(class_names):
        color = box_colors.get(i, (255, 255, 255))
        draw.rectangle([20, y_offset, 40, y_offset+20], outline=color, width=3)
        draw.text((50, y_offset+5), f"Predicted: {class_name}", fill=color, font=font)
        y_offset += 30
    
    legend_path = Path(inference_dir) / "legend.jpg"
    legend_img.save(legend_path, quality=95)
    print(f"ğŸ“‹ Legend saved to: {legend_path}")


def save_yolo_visualization_images(
    yolo_results,
    output_dir,
    config,
    show_gt=False,
    box_color_mode='class',
    confidence_threshold=0.5,
    split='test',
    max_images=None,
    show_labels=False,
    yolo_output_dir=None,
    original_images_dir=None
):
    """
    YOLO predict ê²°ê³¼ë¥¼ ìš°ë¦¬ì˜ ìƒ‰ìƒ ìŠ¤í‚¤ë§ˆë¡œ ì¬ì‹œê°í™”
    
    Args:
        yolo_results: YOLO model.predict() ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (Path ê°ì²´)
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        show_gt: GT í‘œì‹œ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
        box_color_mode: 'class' (í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ) ë˜ëŠ” 'model' (ëª¨ë¸ë³„ ìƒ‰ìƒ)
        confidence_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
        split: ë°ì´í„°ì…‹ split ì´ë¦„
        max_images: ìµœëŒ€ ì €ì¥ ì´ë¯¸ì§€ ìˆ˜ (Noneì´ë©´ ì „ì²´)
        show_labels: í´ë˜ìŠ¤ ë¼ë²¨ í…ìŠ¤íŠ¸ í‘œì‹œ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
    """
    import matplotlib.pyplot as plt
    import matplotlib.patches as patches
    import numpy as np
    
    # ì¸í¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    inference_dir = Path(output_dir) / "inference_images"
    inference_dir.mkdir(parents=True, exist_ok=True)
    
    class_names = config['data']['class_names']
    model_name = config['model']['arch_name']
    
    # max_images ì²˜ë¦¬
    if max_images is None:
        max_images = len(yolo_results)
    
    total_images = min(len(yolo_results), max_images)
    
    # ìƒ‰ìƒ ì„¤ì • (matplotlibìš© - 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”)
    # yolo_predictionsëŠ” í•­ìƒ í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ì‚¬ìš© (COLORS ìƒìˆ˜)
    box_colors_rgb_class = get_class_colors(len(class_names))
    box_colors_class = {i: tuple(c / 255.0 for c in color) for i, color in box_colors_rgb_class.items()}
    
    # inference_imagesëŠ” box_color_modeì— ë”°ë¼
    if box_color_mode == 'model':
        model_color_rgb = get_model_color(model_name)
        model_color = tuple(c / 255.0 for c in model_color_rgb)
        box_colors_inference = {i: model_color for i in range(len(class_names))}
        box_colors_rgb_inference = {i: model_color_rgb for i in range(len(class_names))}
    else:
        box_colors_inference = box_colors_class
        box_colors_rgb_inference = box_colors_rgb_class
    
    print(f"Saving YOLO inference images to: {inference_dir}")
    print(f"Total images to process: {total_images}")
    print(f"Box color mode: {box_color_mode}")
    print(f"Show GT: {show_gt}")
    print(f"Show labels: {show_labels}")
    
    saved_count = 0
    
    for idx, result in enumerate(yolo_results[:total_images]):
        # ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ì°¾ê¸°
        original_image_path = None
        
        # ë°©ë²• 1: original_images_dirì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ì°¾ê¸°
        if original_images_dir is not None:
            if hasattr(result, 'path'):
                # result.pathì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
                result_path = Path(result.path)
                file_name = result_path.name
                original_image_path = Path(original_images_dir) / file_name
                if not original_image_path.exists():
                    # í™•ì¥ì ì œê±° í›„ ë‹¤ì‹œ ì°¾ê¸°
                    base_name = result_path.stem
                    for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:
                        candidate = Path(original_images_dir) / (base_name + ext)
                        if candidate.exists():
                            original_image_path = candidate
                            break
        
        # ë°©ë²• 2: result.pathê°€ ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œì¸ ê²½ìš°
        if original_image_path is None and hasattr(result, 'path'):
            result_path = Path(result.path)
            # yolo_predictions í´ë”ê°€ ì•„ë‹Œ ì›ë³¸ ì´ë¯¸ì§€ í´ë”ì¸ì§€ í™•ì¸
            if 'yolo_predictions' not in str(result_path):
                original_image_path = result_path
        
        # ë°©ë²• 3: resultì—ì„œ ì§ì ‘ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        if original_image_path is None:
            # YOLO result ê°ì²´ì˜ ì†ì„± í™•ì¸
            if hasattr(result, 'source') or hasattr(result, 'im_file'):
                # YOLO v8+ í˜•ì‹
                if hasattr(result, 'im_file'):
                    original_image_path = Path(result.im_file)
                elif hasattr(result, 'source'):
                    original_image_path = Path(result.source)
        
        # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
        if original_image_path is not None and original_image_path.exists():
            # ì›ë³¸ íŒŒì¼ì—ì„œ ì§ì ‘ ë¡œë“œ (100% ì›ë³¸ í’ˆì§ˆ ë³´ì¡´)
            pil_image = Image.open(original_image_path).convert('RGB')
        elif hasattr(result, 'orig_img'):
            # orig_img ì‚¬ìš© (ì´ë¯¸ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì¼ ìˆ˜ ìˆìŒ)
            img_array = result.orig_img
            if isinstance(img_array, np.ndarray):
                if img_array.dtype != np.uint8:
                    if img_array.max() <= 1.0:
                        img_array = (img_array * 255).astype(np.uint8)
                    else:
                        img_array = img_array.astype(np.uint8)
                pil_image = Image.fromarray(img_array)
            else:
                pil_image = img_array
        else:
            print(f"Warning: Could not find original image for result {idx}")
            continue
        
        # Predictions ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        xyxy_filtered = []
        confidences_filtered = []
        class_ids_filtered = []
        
        if hasattr(result, 'boxes') and result.boxes is not None:
            boxes = result.boxes
            
            if hasattr(boxes, 'xyxy') and hasattr(boxes, 'conf') and hasattr(boxes, 'cls'):
                xyxy = boxes.xyxy.cpu().numpy()
                confidences = boxes.conf.cpu().numpy()
                class_ids = boxes.cls.cpu().numpy().astype(int)
                
                # ì„ê³„ê°’ ì ìš©
                keep = confidences >= confidence_threshold
                xyxy_filtered = xyxy[keep]
                confidences_filtered = confidences[keep]
                class_ids_filtered = class_ids[keep]
        
        # inference_imagesìš© ì´ë¯¸ì§€ ìƒì„± (PIL ImageDraw ì‚¬ìš©)
        img_inference = pil_image.copy()
        draw_inference = ImageDraw.Draw(img_inference)
        
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 16)
        except:
            font = ImageFont.load_default()
        
        # inference_imagesìš© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for box, label_id, score in zip(xyxy_filtered, class_ids_filtered, confidences_filtered):
            x1, y1, x2, y2 = float(box[0]), float(box[1]), float(box[2]), float(box[3])
            
            # ìƒ‰ìƒ ê°€ì ¸ì˜¤ê¸° (RGB íŠœí”Œ)
            color_rgb = box_colors_rgb_inference.get(label_id, (255, 255, 255))
            
            # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            draw_inference.rectangle([x1, y1, x2, y2], outline=color_rgb, width=8)
            
            # ë¼ë²¨ í…ìŠ¤íŠ¸
            if show_labels and label_id < len(class_names):
                text = f"{class_names[label_id]}: {score:.2f}"
                bbox = draw_inference.textbbox((x1, y1 - 20), text, font=font)
                draw_inference.rectangle(bbox, fill=color_rgb)
                draw_inference.text((x1, y1 - 20), text, fill="white", font=font)
        
        # inference_images ì €ì¥ (ì›ë³¸ í’ˆì§ˆ ë³´ì¡´)
        filename = f"inference_{idx:04d}_{split}.jpg"
        save_path = inference_dir / filename
        img_inference.save(save_path, quality=95, optimize=False)
        
        # yolo_predictionsì—ë„ ì €ì¥ (í•­ìƒ í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ, COLORS ìƒìˆ˜ ì‚¬ìš©)
        if yolo_output_dir is not None and hasattr(result, 'path'):
            result_path = Path(result.path)
            yolo_file_name = result_path.name
            yolo_save_path = Path(yolo_output_dir) / yolo_file_name
            
            if yolo_save_path.exists():
                # yolo_predictionsìš© ì´ë¯¸ì§€ ìƒì„± (í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ)
                img_yolo = pil_image.copy()
                draw_yolo = ImageDraw.Draw(img_yolo)
                
                # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒìœ¼ë¡œ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                for box, label_id, score in zip(xyxy_filtered, class_ids_filtered, confidences_filtered):
                    x1, y1, x2, y2 = float(box[0]), float(box[1]), float(box[2]), float(box[3])
                    
                    # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ (RGB íŠœí”Œ)
                    color_rgb_class = box_colors_rgb_class.get(label_id, (255, 255, 255))
                    
                    # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                    draw_yolo.rectangle([x1, y1, x2, y2], outline=color_rgb_class, width=8)
                
                # yolo_predictions í´ë”ì— ì €ì¥ (ì›ë³¸ í’ˆì§ˆ ë³´ì¡´)
                img_yolo.save(yolo_save_path, quality=95, optimize=False)
        
        saved_count += 1
        
        if saved_count % 10 == 0:
            print(f"  Saved {saved_count}/{total_images} images...")
    
    print(f" Saved {saved_count} YOLO inference images to: {inference_dir}")
    
    # ë²”ë¡€ ì´ë¯¸ì§€ ìƒì„±
    create_legend_image(inference_dir, class_names, box_colors_rgb_class, model_name, show_gt)
    
    return inference_dir