{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb465c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import platform\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import Counter, OrderedDict\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import transformers\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d58e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ ÌÉêÏÉâ\n",
    "\n",
    "# Ìïú Î≤àÎßå Ï∞æÍ≥† Í≥†Ï†ï\n",
    "def find_project_root(marker_filename=\".project-root\"):\n",
    "    current_dir = os.path.abspath(os.getcwd())\n",
    "    while True:\n",
    "        if os.path.isfile(os.path.join(current_dir, marker_filename)):\n",
    "            return current_dir\n",
    "        parent_dir = os.path.dirname(current_dir)\n",
    "        if parent_dir == current_dir:\n",
    "            raise FileNotFoundError(f\"Could not find {marker_filename} in any parent directory.\")\n",
    "        current_dir = parent_dir\n",
    "        \n",
    "# Í≤ΩÎ°ú/Ï∂úÎ†• Ìè¥Îçî ÏÉùÏÑ±(find_project_root() Ìò∏Ï∂ú ÌõÑ ÏÇ¨Ïö©)\n",
    "def ensure_dir(path):\n",
    "    # ÎîîÎ†âÌÜ†Î¶¨ ÏóÜÏúºÎ©¥ ÏÉùÏÑ±\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "def get_project_path(*paths):\n",
    "    return os.path.join(PROJECT_ROOT, *paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENTAL ENVIRONMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ÌïòÎìúÏõ®Ïñ¥ Ï†ïÎ≥¥\n",
    "print(\"\\n[Hardware]\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"  Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"  GPU: {gpu_name}\")\n",
    "    print(f\"  GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    if torch.backends.cudnn.is_available():\n",
    "        print(f\"  cuDNN Version: {torch.backends.cudnn.version()}\")\n",
    "\n",
    "# CPU Ï†ïÎ≥¥\n",
    "print(f\"  CPU: {platform.processor()}\")\n",
    "print(f\"  CPU Cores: {os.cpu_count()}\")\n",
    "\n",
    "# ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ Ï†ïÎ≥¥\n",
    "print(\"\\n[Software]\")\n",
    "print(f\"  OS: {platform.system()} {platform.release()}\")\n",
    "print(f\"  Python: {platform.python_version()}\")\n",
    "print(f\"  PyTorch: {torch.__version__}\")\n",
    "print(f\"  Torchvision: {torchvision.__version__}\")\n",
    "print(f\"  Transformers: {transformers.__version__}\")\n",
    "print(f\"  PyTorch Lightning: {pl.__version__}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Environment check completed\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57180ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Management & Logging\n",
    "\n",
    "# ============================================================\n",
    "# Cell: Experiment Manager\n",
    "# ============================================================\n",
    "\n",
    "class ExperimentManager:\n",
    "    \"\"\"Ïã§Ìóò Í¥ÄÎ¶¨ Î∞è ÏûêÎèô Î°úÍ∑∏ Ï†ÄÏû•\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ConfigDict):\n",
    "        self.config = config\n",
    "        \n",
    "        # Experiment ID ÏÉùÏÑ± (ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ)\n",
    "        self.experiment_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Ïã§Ìóò ÎîîÎ†âÌÜ†Î¶¨ Íµ¨Ï°∞: exp/{model}/{dataset}/{exp_id}\n",
    "        self.exp_dir = Path(config.experiment.save_dir) / \\\n",
    "                       config.model.arch_name / \\\n",
    "                       config.data.dataset_name / \\\n",
    "                       self.experiment_id\n",
    "        \n",
    "        # ÌïòÏúÑ ÎîîÎ†âÌÜ†Î¶¨\n",
    "        self.config_dir = self.exp_dir / \"config\"\n",
    "        self.checkpoint_dir = self.exp_dir / \"checkpoints\"\n",
    "        self.tensorboard_dir = self.exp_dir / \"tensorboard\"\n",
    "        self.results_dir = self.exp_dir / \"results\"\n",
    "        \n",
    "        # ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±\n",
    "        self._create_directories()\n",
    "        \n",
    "        # ConfigÏôÄ metadata Ï†ÄÏû•\n",
    "        self._save_experiment_info()\n",
    "    \n",
    "    def _create_directories(self):\n",
    "        \"\"\"Ïã§Ìóò Ìè¥Îçî ÏÉùÏÑ±\"\"\"\n",
    "        for directory in [self.config_dir, self.checkpoint_dir, \n",
    "                         self.tensorboard_dir, self.results_dir]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def _save_experiment_info(self):\n",
    "        \"\"\"Config Î∞è Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï†ÄÏû•\"\"\"\n",
    "        # Config Ï†ÄÏû•\n",
    "        save_config(self.config, self.config_dir / \"config.yaml\")\n",
    "        \n",
    "        # Metadata Ï†ÄÏû•\n",
    "        metadata = {\n",
    "            'experiment_id': self.experiment_id,\n",
    "            'created_at': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'exp_dir': str(self.exp_dir),\n",
    "            'model': self.config.model.arch_name,\n",
    "            'dataset': self.config.data.dataset_name,\n",
    "            'num_classes': self.config.data.num_classes,\n",
    "        }\n",
    "        save_config(metadata, self.config_dir / \"metadata.yaml\")\n",
    "    \n",
    "    def save_results(self, results: Dict[str, Any]):\n",
    "        \"\"\"Ïã§Ìóò Í≤∞Í≥º Ï†ÄÏû•\"\"\"\n",
    "        save_config(results, self.results_dir / \"results.yaml\")\n",
    "    \n",
    "    def print_info(self):\n",
    "        \"\"\"Ïã§Ìóò Ï†ïÎ≥¥ Ï∂úÎ†•\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üß™ EXPERIMENT SETUP\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"  Experiment ID:   {self.experiment_id}\")\n",
    "        print(f\"  Name:            {self.config.experiment.name}\")\n",
    "        print(f\"  Model:           {self.config.model.arch_name}\")\n",
    "        print(f\"  Dataset:         {self.config.data.dataset_name} \"\n",
    "              f\"({self.config.data.num_classes} classes)\")\n",
    "        print(f\"  Classes:         {', '.join(self.config.data.class_names)}\")\n",
    "        print(f\"\")\n",
    "        print(f\"  üìÅ Directories:\")\n",
    "        print(f\"     Root:         {self.exp_dir}\")\n",
    "        print(f\"     Config:       {self.config_dir}\")\n",
    "        print(f\"     Checkpoints:  {self.checkpoint_dir}\")\n",
    "        print(f\"     TensorBoard:  {self.tensorboard_dir}\")\n",
    "        print(f\"     Results:      {self.results_dir}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(\"‚úÖ Experiment Manager Î°úÎìú ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e39be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# DETR Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "# ==========================\n",
    "\n",
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    \"\"\"\n",
    "    DETR ÌïôÏäµÏùÑ ÏúÑÌïú Ïª§Ïä§ÌÖÄ COCO Detection Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        img_folder: str, \n",
    "        ann_file: str,\n",
    "        imageprocessor: DetrImageProcessor, \n",
    "        train: bool = True\n",
    "    ):\n",
    "        super(CocoDetection, self).__init__(img_folder, ann_file)\n",
    "        \n",
    "        self.imageprocessor = imageprocessor\n",
    "        self.train = train\n",
    "        \n",
    "        # ÌïôÏäµ Ïãú ÏÉâÏÉÅ/Î∏îÎü¨ Í∏∞Î∞ò Ï¶ùÍ∞ï Ï†ÅÏö© (bbox ÏàòÏ†ï Î∂àÌïÑÏöî)\n",
    "        self.augment = (\n",
    "            T.Compose([\n",
    "                T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "                T.RandomAdjustSharpness(sharpness_factor=1.5, p=0.2),\n",
    "            ])\n",
    "            if train\n",
    "            else None\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # PIL Ïù¥ÎØ∏ÏßÄÏôÄ COCO ÌòïÏãùÏùò ÌÉÄÍ≤ü ÏùΩÍ∏∞\n",
    "        img, target = super(CocoDetection, self).__getitem__(idx)\n",
    "\n",
    "        # ÌïôÏäµ Ïãú Ïù¥ÎØ∏ÏßÄ Ï¶ùÍ∞ï\n",
    "        if self.augment is not None:\n",
    "            img = self.augment(img)\n",
    "\n",
    "        # DETR ÌòïÏãùÏúºÎ°ú Ïù¥ÎØ∏ÏßÄÏôÄ ÌÉÄÍ≤ü Ï†ÑÏ≤òÎ¶¨\n",
    "        image_id = self.ids[idx]\n",
    "        target = {'image_id': image_id, 'annotations': target}\n",
    "        encoding = self.imageprocessor(images=img, annotations=target, return_tensors=\"pt\")\n",
    "        \n",
    "        # Î∞∞Ïπò Ï∞®Ïõê Ï†úÍ±∞\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
    "        target = encoding[\"labels\"][0]\n",
    "\n",
    "        return pixel_values, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "\n",
    "# =========================\n",
    "# DataLoader ÏÉùÏÑ±\n",
    "# =========================\n",
    "\n",
    "# DETR ImageProcessor Ï¥àÍ∏∞Ìôî\n",
    "imageprocessor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "def create_collate_fn(imageprocessor: DetrImageProcessor):\n",
    "    \"\"\"Î∞∞Ïπò collate Ìï®Ïàò (Ìå®Îî© Ï†ÅÏö©)\"\"\"\n",
    "    def collate_fn(batch):\n",
    "        pixel_values = [item[0] for item in batch]\n",
    "        labels = [item[1] for item in batch]\n",
    "        \n",
    "        # imageprocessorÎ°ú Ìå®Îî© Ï†ÅÏö©\n",
    "        encoding = imageprocessor.pad(pixel_values, return_tensors=\"pt\")\n",
    "        \n",
    "        return {\n",
    "            'pixel_values': encoding['pixel_values'],\n",
    "            'pixel_mask': encoding['pixel_mask'],\n",
    "            'labels': labels\n",
    "        }\n",
    "    return collate_fn\n",
    "# WLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e466ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETR Model \n",
    "\n",
    "# =========================================\n",
    "# DETR Î™®Îç∏ Î°úÎìú (ÏÇ¨Ï†ÑÌïôÏäµ Î™®Îç∏)\n",
    "# =========================================\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "class Detr(pl.LightningModule):\n",
    "    \"\"\"PyTorch Lightning Î™®ÎìàÎ°ú Íµ¨ÌòÑÌïú DETR ÌïôÏäµ ÎûòÌçº\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_labels: int,\n",
    "        lr: float = 1e-4,\n",
    "        lr_backbone: float = 1e-5,\n",
    "        weight_decay: float = 1e-4,\n",
    "        score_threshold: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = DetrForObjectDetection.from_pretrained(\n",
    "            \"facebook/detr-resnet-50\",\n",
    "            num_labels=num_labels,\n",
    "            ignore_mismatched_sizes=True,\n",
    "        )\n",
    "\n",
    "        self.map_metric = MeanAveragePrecision(\n",
    "            box_format=\"cxcywh\", iou_type=\"bbox\", class_metrics=True\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values, pixel_mask=None):\n",
    "        return self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "    def common_step(self, batch, batch_idx):\n",
    "        pixel_values = batch[\"pixel_values\"]\n",
    "        pixel_mask = batch.get(\"pixel_mask\")\n",
    "        labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "        outputs = self.model(\n",
    "            pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels\n",
    "        )\n",
    "        return outputs.loss, outputs.loss_dict\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        for k, v in loss_dict.items():\n",
    "            self.log(f\"train_{k}\", v.item())\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        for k, v in loss_dict.items():\n",
    "            self.log(f\"val_{k}\", v.item())\n",
    "\n",
    "        # mAP Í≥ÑÏÇ∞\n",
    "        with torch.no_grad():\n",
    "            labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "            outputs = self.model(\n",
    "                pixel_values=batch[\"pixel_values\"], \n",
    "                pixel_mask=batch.get(\"pixel_mask\")\n",
    "            )\n",
    "            self._update_map(outputs, labels)\n",
    "        return loss\n",
    "\n",
    "    def _update_map(self, outputs, labels):\n",
    "        \"\"\"mAP ÏóÖÎç∞Ïù¥Ìä∏\"\"\"\n",
    "        probs = outputs.logits.softmax(-1)[..., :-1]\n",
    "        scores, pred_labels = probs.max(-1)\n",
    "        pred_boxes = outputs.pred_boxes\n",
    "\n",
    "        preds = []\n",
    "        targets = []\n",
    "\n",
    "        for i in range(pred_boxes.shape[0]):\n",
    "            keep = scores[i] > self.hparams.score_threshold\n",
    "            preds.append({\n",
    "                \"boxes\": pred_boxes[i][keep].detach().cpu(),\n",
    "                \"scores\": scores[i][keep].detach().cpu(),\n",
    "                \"labels\": pred_labels[i][keep].detach().cpu(),\n",
    "            })\n",
    "            targets.append({\n",
    "                \"boxes\": labels[i][\"boxes\"].detach().cpu(),\n",
    "                \"labels\": labels[i][\"class_labels\"].detach().cpu(),\n",
    "            })\n",
    "\n",
    "        if preds:\n",
    "            self.map_metric.update(preds, targets)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.map_metric.compute()\n",
    "        for k, v in metrics.items():\n",
    "            if torch.is_tensor(v) and v.ndim == 0:\n",
    "                self.log(f\"val_{k}\", v, prog_bar=True)\n",
    "        self.map_metric.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        param_dicts = [\n",
    "            {\"params\": [p for n, p in self.named_parameters() \n",
    "                       if \"backbone\" not in n and p.requires_grad]},\n",
    "            {\"params\": [p for n, p in self.named_parameters() \n",
    "                       if \"backbone\" in n and p.requires_grad],\n",
    "             \"lr\": self.hparams.lr_backbone},\n",
    "        ]\n",
    "        return torch.optim.AdamW(\n",
    "            param_dicts, lr=self.hparams.lr, weight_decay=self.hparams.weight_decay\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad8024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell: ÌÜµÌï© Ïã§Ìóò Ïã§Ìñâ Ìï®Ïàò\n",
    "# ============================================================\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, CSVLogger\n",
    "\n",
    "def run_experiment(config: ConfigDict):\n",
    "    \"\"\"Config Í∏∞Î∞ò Ï†ÑÏ≤¥ Ïã§Ìóò Ïã§Ìñâ\"\"\"\n",
    "    \n",
    "    # 1. Experiment Manager ÏÉùÏÑ±\n",
    "    exp_manager = ExperimentManager(config)\n",
    "    exp_manager.print_info()\n",
    "    \n",
    "    # 2. Seed ÏÑ§Ï†ï (Ïû¨ÌòÑÏÑ±)\n",
    "    pl.seed_everything(config.experiment.seed)\n",
    "    print(f\" Seed set to: {config.experiment.seed}\\n\")\n",
    "    \n",
    "    # 3. ImageProcessor Ï¥àÍ∏∞Ìôî\n",
    "    imageprocessor = DetrImageProcessor.from_pretrained(\n",
    "        config.model.pretrained_path\n",
    "    )\n",
    "    print(f\" ImageProcessor loaded: {config.model.pretrained_path}\\n\")\n",
    "    \n",
    "    # 4. Dataset ÏÉùÏÑ± (Registry ÏÇ¨Ïö©)\n",
    "    print(\" Creating datasets...\")\n",
    "    train_dataset = create_dataset_from_config(\n",
    "        config.data.dataset_name, \"train\", imageprocessor, config\n",
    "    )\n",
    "    val_dataset = create_dataset_from_config(\n",
    "        config.data.dataset_name, \"val\", imageprocessor, config\n",
    "    )\n",
    "    print(f\"   Train: {len(train_dataset)} samples\")\n",
    "    print(f\"   Val:   {len(val_dataset)} samples\\n\")\n",
    "    \n",
    "    # 5. DataLoader ÏÉùÏÑ±\n",
    "    print(\" Creating dataloaders...\")\n",
    "    collate_fn = create_collate_fn(imageprocessor)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.data.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=config.data.num_workers,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.data.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.data.num_workers,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    print(f\"   Train batches: {len(train_loader)}\")\n",
    "    print(f\"   Val batches:   {len(val_loader)}\\n\")\n",
    "    \n",
    "    # 6. Î™®Îç∏ ÏÉùÏÑ±\n",
    "    print(\" Creating model...\")\n",
    "    model = Detr(\n",
    "        num_labels=config.model.num_labels,\n",
    "        lr=config.model.learning_rate,\n",
    "        lr_backbone=config.model.lr_backbone,\n",
    "        weight_decay=config.model.weight_decay,\n",
    "        score_threshold=config.model.score_threshold\n",
    "    )\n",
    "    print(f\"   Model: DETR with {config.model.num_labels} classes\\n\")\n",
    "    \n",
    "    # 7. Callbacks ÏÑ§Ï†ï\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=str(exp_manager.checkpoint_dir),\n",
    "        filename='best-{epoch:02d}-{val_loss:.2f}',\n",
    "        save_top_k=config.trainer.checkpoint.save_top_k,\n",
    "        monitor=config.trainer.checkpoint.monitor,\n",
    "        mode=config.trainer.checkpoint.mode,\n",
    "        save_last=config.trainer.checkpoint.save_last\n",
    "    )\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor=config.trainer.early_stopping.monitor,\n",
    "        patience=config.trainer.early_stopping.patience,\n",
    "        mode=config.trainer.early_stopping.mode\n",
    "    )\n",
    "    \n",
    "    # 8. Loggers ÏÑ§Ï†ï\n",
    "    tensorboard_logger = TensorBoardLogger(\n",
    "        save_dir=str(exp_manager.tensorboard_dir),\n",
    "        name=\"\",\n",
    "        version=\"\"\n",
    "    )\n",
    "    \n",
    "    csv_logger = CSVLogger(\n",
    "        save_dir=str(exp_manager.exp_dir),\n",
    "        name=\"logs\"\n",
    "    )\n",
    "    \n",
    "    # 9. Trainer ÏÑ§Ï†ï\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.trainer.max_epochs,\n",
    "        accelerator=config.trainer.accelerator,\n",
    "        devices=config.trainer.devices,\n",
    "        precision=config.trainer.precision,\n",
    "        log_every_n_steps=10,\n",
    "        accumulate_grad_batches=config.trainer.accumulate_grad_batches,\n",
    "        gradient_clip_val=config.trainer.gradient_clip_val,\n",
    "        callbacks=[checkpoint_callback, early_stop_callback],\n",
    "        logger=[tensorboard_logger, csv_logger],\n",
    "        enable_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    # 10. ÌïôÏäµ Ï†ïÎ≥¥ Ï∂úÎ†•\n",
    "    effective_batch = config.data.batch_size * config.trainer.accumulate_grad_batches\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\" TRAINING CONFIGURATION\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Max Epochs:          {config.trainer.max_epochs}\")\n",
    "    print(f\"  Batch Size:          {config.data.batch_size}\")\n",
    "    print(f\"  Gradient Accum:      {config.trainer.accumulate_grad_batches}\")\n",
    "    print(f\"  Effective Batch:     {effective_batch}\")\n",
    "    print(f\"  Learning Rate:       {config.model.learning_rate}\")\n",
    "    print(f\"  LR Backbone:         {config.model.lr_backbone}\")\n",
    "    print(f\"  Precision:           {config.trainer.precision}\")\n",
    "    print(f\"  Early Stop Patience: {config.trainer.early_stopping.patience}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # 11. ÌïôÏäµ ÏãúÏûë\n",
    "    print(\" Starting training...\\n\")\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    \n",
    "    # 12. Í≤∞Í≥º Ï†ÄÏû•\n",
    "    results = {\n",
    "        'experiment_id': exp_manager.experiment_id,\n",
    "        'best_checkpoint': str(checkpoint_callback.best_model_path),\n",
    "        'best_val_loss': float(checkpoint_callback.best_model_score) \n",
    "                        if checkpoint_callback.best_model_score else None,\n",
    "        'total_epochs': trainer.current_epoch,\n",
    "        'config_path': str(exp_manager.config_dir / \"config.yaml\")\n",
    "    }\n",
    "    exp_manager.save_results(results)\n",
    "    \n",
    "    # 13. ÏôÑÎ£å Î©îÏãúÏßÄ\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\" TRAINING COMPLETED!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Experiment ID:   {exp_manager.experiment_id}\")\n",
    "    print(f\"  Best Checkpoint: {checkpoint_callback.best_model_path}\")\n",
    "    print(f\"  Best Val Loss:   {checkpoint_callback.best_model_score:.4f}\")\n",
    "    print(f\"\")\n",
    "    print(f\"   All results saved in:\")\n",
    "    print(f\"     {exp_manager.exp_dir}\")\n",
    "    print(f\"\")\n",
    "    print(f\"   View TensorBoard:\")\n",
    "    print(f\"     tensorboard --logdir {exp_manager.tensorboard_dir}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return exp_manager, trainer, model\n",
    "\n",
    "print(\"‚úÖ ÌÜµÌï© Ïã§Ìóò Ìï®Ïàò Î°úÎìú ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†ÄÏû•Îêú Ïã§Ìóò Ïû¨ÌòÑ \n",
    "\n",
    "# Config Î°úÎìú\n",
    "config \n",
    "\n",
    "# ÎèôÏùºÌïú ÏÑ§Ï†ïÏúºÎ°ú Ïû¨Ïã§Ìóò\n",
    "exp_manager, trainer, model = run_experiment(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f77ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ÏóêÏÑú Î™®Îç∏ Î°úÎìú\n",
    "\n",
    "model = Detr.load_from_checkpoint(\n",
    "    \"exp/detr/TomatOD_COCO_3/20250101_123456/checkpoints/best-epoch=10-val_loss=1.23.ckpt\",\n",
    "    num_labels=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
