{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cab1cef",
   "metadata": {},
   "source": [
    "## Grounding DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ea55f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeonjin/tomato-detection-agentic/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/hyeonjin/tomato-detection-agentic/.venv/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu118\n",
      "CUDA available: True\n",
      "GPU: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "# 환경 설정 및 라이브러리 import \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'  # GPU 설정\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Grounding DINO 관련\n",
    "try:\n",
    "    from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "    from groundingdino.util import box_ops\n",
    "    import groundingdino.datasets.transforms as T\n",
    "    GROUNDING_DINO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Grounding DINO가 설치되지 않았습니다.\")\n",
    "    print(\"설치: pip install groundingdino-py\")\n",
    "    GROUNDING_DINO_AVAILABLE = False\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4829c6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/hyeonjin/tomato-detection-agentic\n",
      "Test images: /home/hyeonjin/tomato-detection-agentic/data/TomatOD_COCO_3/test/images\n",
      "Output dir: /home/hyeonjin/tomato-detection-agentic/notebook/results/grounding_dino\n"
     ]
    }
   ],
   "source": [
    "# 프로젝트 루트 탐색\n",
    "def find_project_root(marker_filename=\".project-root\"):\n",
    "    current_dir = os.path.abspath(os.getcwd())\n",
    "    while True:\n",
    "        if os.path.isfile(os.path.join(current_dir, marker_filename)):\n",
    "            return current_dir\n",
    "        parent_dir = os.path.dirname(current_dir)\n",
    "        if parent_dir == current_dir:\n",
    "            raise FileNotFoundError(f\"Could not find {marker_filename}\")\n",
    "        current_dir = parent_dir\n",
    "\n",
    "def ensure_dir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "def get_project_path(*paths):\n",
    "    return os.path.join(PROJECT_ROOT, *paths)\n",
    "\n",
    "# 데이터 경로\n",
    "coco_path = get_project_path(\"data\", \"TomatOD_COCO_3\")\n",
    "test_path = os.path.join(coco_path, \"test\")\n",
    "test_images_dir = os.path.join(test_path, \"images\")\n",
    "test_ann_file = os.path.join(test_path, \"custom_test.json\")\n",
    "\n",
    "# 출력 경로\n",
    "output_dir = get_project_path(\"notebook\", \"results\", \"grounding_dino\")\n",
    "ensure_dir(output_dir)\n",
    "ensure_dir(os.path.join(output_dir, \"predictions\"))\n",
    "ensure_dir(os.path.join(output_dir, \"visualizations\"))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Test images: {test_images_dir}\")\n",
    "print(f\"Output dir: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbc905cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config path: /home/hyeonjin/tomato-detection-agentic/configs/gdino/gdino_3class.py\n",
      "Weights path: /home/hyeonjin/tomato-detection-agentic/weights/groundingdino_swint_ogc.pth\n",
      "❌ 모델 로드 실패: There are syntax errors in config file /home/hyeonjin/tomato-detection-agentic/configs/gdino/gdino_3class.py\n",
      "수동으로 모델을 다운로드하거나 경로를 확인하세요.\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "PROJECT_ROOT = find_project_root()\n",
    "CONFIG_PATH = get_project_path(\"configs\", \"gdino\", \"gdino_3class.yaml\")\n",
    "WEIGHTS_PATH = get_project_path(\"weights\", \"groundingdino_swint_ogc.pth\")\n",
    "py_config_path = get_project_path(\"configs\", \"gdino\", \"gdino_3class.py\")\n",
    "\n",
    "# YAML을 읽어서 Python 파일로 변환\n",
    "# 파일을 그대로 읽어서 Python 파일로 저장\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config_content = f.read()\n",
    "\n",
    "# Python config 파일로 저장\n",
    "with open(py_config_path, 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "CONFIG_PATH = py_config_path\n",
    "WEIGHTS_PATH = get_project_path(\"weights\", \"groundingdino_swint_ogc.pth\")\n",
    "\n",
    "print(f\"Config path: {CONFIG_PATH}\")\n",
    "print(f\"Weights path: {WEIGHTS_PATH}\")\n",
    "\n",
    "\n",
    "# 모델 로드\n",
    "if GROUNDING_DINO_AVAILABLE:\n",
    "    try:\n",
    "        model = load_model(CONFIG_PATH, WEIGHTS_PATH, device='cuda')\n",
    "        model.eval()\n",
    "        print(\"✅ Grounding DINO 모델 로드 완료\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 모델 로드 실패: {e}\")\n",
    "        print(\"수동으로 모델을 다운로드하거나 경로를 확인하세요.\")\n",
    "        model = None\n",
    "else:\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb758100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 모델이 로드되지 않았습니다.\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 엔지니어링: 클래스별 개별 추론\n",
    "\n",
    "# 클래스 정의\n",
    "CLASS_NAMES = ['fully-ripe', 'semi-ripe', 'unripe']\n",
    "CLASS_COLORS = ['#D0021B', '#F8E71C', '#7ED321']  # 빨강, 노랑, 초록\n",
    "\n",
    "def predict_with_grounding_dino_per_class(\n",
    "    model,\n",
    "    image_path: str,\n",
    "    class_name: str,\n",
    "    box_threshold: float = 0.3,\n",
    "    text_threshold: float = 0.25\n",
    ") -> Tuple[np.ndarray, np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    단일 클래스에 대해 Grounding DINO로 예측 수행\n",
    "    \n",
    "    Returns:\n",
    "        boxes: (N, 4) numpy array [x1, y1, x2, y2] (정규화된 좌표)\n",
    "        scores: (N,) numpy array\n",
    "        label: 클래스 인덱스\n",
    "    \"\"\"\n",
    "    # 단일 클래스 프롬프트\n",
    "    text_prompt = f\"{class_name} tomato.\"\n",
    "    \n",
    "    # 이미지 로드 및 전처리\n",
    "    image_source, image = load_image(image_path)\n",
    "    \n",
    "    # 예측 수행\n",
    "    boxes, logits, phrases = predict(\n",
    "        model=model,\n",
    "        image=image,\n",
    "        caption=text_prompt,\n",
    "        box_threshold=box_threshold,\n",
    "        text_threshold=text_threshold\n",
    "    )\n",
    "    \n",
    "    # 클래스 인덱스 찾기\n",
    "    class_idx = CLASS_NAMES.index(class_name)\n",
    "    \n",
    "    # 모든 박스에 동일한 라벨 할당\n",
    "    labels = np.full(len(boxes), class_idx)\n",
    "    \n",
    "    return boxes, logits, labels\n",
    "\n",
    "# 배치 추론 실행 (클래스별 개별 추론)\n",
    "all_results = []\n",
    "\n",
    "BOX_THRESHOLD = 0.3\n",
    "TEXT_THRESHOLD = 0.25\n",
    "MIN_BOX_AREA = 100\n",
    "MAX_BOX_AREA_RATIO = 0.8\n",
    "\n",
    "if model is not None:\n",
    "    for img_id, img_path, file_name in tqdm(test_image_files, desc=\"추론 중\"):\n",
    "        try:\n",
    "            # 이미지 정보 가져오기\n",
    "            img_info = image_id_to_info[img_id]\n",
    "            img_width = img_info['width']\n",
    "            img_height = img_info['height']\n",
    "            img_area = img_width * img_height\n",
    "            \n",
    "            # 모든 클래스에 대해 개별 추론\n",
    "            all_boxes = []\n",
    "            all_scores = []\n",
    "            all_labels = []\n",
    "            \n",
    "            for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "                # 각 클래스별로 개별 추론\n",
    "                boxes, scores, labels = predict_with_grounding_dino_per_class(\n",
    "                    model=model,\n",
    "                    image_path=img_path,\n",
    "                    class_name=class_name,\n",
    "                    box_threshold=BOX_THRESHOLD,\n",
    "                    text_threshold=TEXT_THRESHOLD\n",
    "                )\n",
    "                \n",
    "                # 박스를 COCO 형식으로 변환 및 필터링\n",
    "                for i in range(len(boxes)):\n",
    "                    x1, y1, x2, y2 = boxes[i]\n",
    "                    \n",
    "                    # 정규화된 좌표를 픽셀 좌표로 변환\n",
    "                    x1 = int(x1 * img_width)\n",
    "                    y1 = int(y1 * img_height)\n",
    "                    x2 = int(x2 * img_width)\n",
    "                    y2 = int(y2 * img_height)\n",
    "                    \n",
    "                    # 박스 크기 계산\n",
    "                    w = x2 - x1\n",
    "                    h = y2 - y1\n",
    "                    box_area = w * h\n",
    "                    \n",
    "                    # 필터링\n",
    "                    if box_area < MIN_BOX_AREA:\n",
    "                        continue\n",
    "                    if box_area > img_area * MAX_BOX_AREA_RATIO:\n",
    "                        continue\n",
    "                    \n",
    "                    # 이미지 범위 내인지 확인 및 클리핑\n",
    "                    if x1 < 0 or y1 < 0 or x2 > img_width or y2 > img_height:\n",
    "                        x1 = max(0, min(x1, img_width))\n",
    "                        y1 = max(0, min(y1, img_height))\n",
    "                        x2 = max(0, min(x2, img_width))\n",
    "                        y2 = max(0, min(y2, img_height))\n",
    "                        w = x2 - x1\n",
    "                        h = y2 - y1\n",
    "                        if w * h < MIN_BOX_AREA:\n",
    "                            continue\n",
    "                    \n",
    "                    # COCO 형식: [x, y, width, height]\n",
    "                    coco_box = [x1, y1, w, h]\n",
    "                    all_boxes.append(coco_box)\n",
    "                    all_scores.append(float(scores[i]))\n",
    "                    all_labels.append(int(labels[i]))\n",
    "            \n",
    "            # 결과 저장\n",
    "            result = {\n",
    "                'image_id': img_id,\n",
    "                'file_name': file_name,\n",
    "                'boxes': all_boxes,\n",
    "                'scores': all_scores,\n",
    "                'labels': all_labels\n",
    "            }\n",
    "            all_results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {file_name} 처리 실패: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"✅ 추론 완료: {len(all_results)}개 이미지\")\n",
    "else:\n",
    "    print(\"❌ 모델이 로드되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34046c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 함수 정의\n",
    "\n",
    "def predict_with_grounding_dino(\n",
    "    model,\n",
    "    image_path: str,\n",
    "    text_prompt: str,\n",
    "    box_threshold: float = 0.3,\n",
    "    text_threshold: float = 0.25\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Grounding DINO로 예측 수행\n",
    "    \n",
    "    Returns:\n",
    "        boxes: (N, 4) numpy array [x1, y1, x2, y2]\n",
    "        scores: (N,) numpy array\n",
    "        labels: (N,) numpy array (class indices)\n",
    "    \"\"\"\n",
    "    # 이미지 로드 및 전처리\n",
    "    image_source, image = load_image(image_path)\n",
    "    \n",
    "    # 예측 수행\n",
    "    boxes, logits, phrases = predict(\n",
    "        model=model,\n",
    "        image=image,\n",
    "        caption=text_prompt,\n",
    "        box_threshold=box_threshold,\n",
    "        text_threshold=text_threshold\n",
    "    )\n",
    "    \n",
    "    # phrases를 클래스 인덱스로 변환\n",
    "    labels = []\n",
    "    for phrase in phrases:\n",
    "        # phrase에서 클래스 이름 추출 (예: \"fully-ripe tomato\" -> \"fully-ripe\")\n",
    "        phrase_lower = phrase.lower()\n",
    "        class_idx = -1\n",
    "        for idx, class_name in enumerate(CLASS_NAMES):\n",
    "            if class_name in phrase_lower:\n",
    "                class_idx = idx\n",
    "                break\n",
    "        if class_idx == -1:\n",
    "            class_idx = 0  # 기본값\n",
    "        labels.append(class_idx)\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return boxes, logits, labels\n",
    "\n",
    "# 테스트 이미지 경로 수집\n",
    "test_image_files = []\n",
    "for img_id, file_name in image_id_to_file.items():\n",
    "    img_path = os.path.join(test_images_dir, file_name)\n",
    "    if os.path.exists(img_path):\n",
    "        test_image_files.append((img_id, img_path, file_name))\n",
    "\n",
    "print(f\"테스트 이미지 수: {len(test_image_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08451c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 추론 실행 (박스 필터링 강화)\n",
    "\n",
    "# 추론 결과 저장\n",
    "predictions = []\n",
    "all_results = []\n",
    "\n",
    "BOX_THRESHOLD = 0.3\n",
    "TEXT_THRESHOLD = 0.25\n",
    "MIN_BOX_AREA = 100  # 최소 박스 면적 (너무 작은 박스 제거)\n",
    "MAX_BOX_AREA_RATIO = 0.8  # 최대 박스 면적 비율 (이미지의 80% 이상은 제거)\n",
    "\n",
    "if model is not None:\n",
    "    for img_id, img_path, file_name in tqdm(test_image_files, desc=\"추론 중\"):\n",
    "        try:\n",
    "            # 예측 수행\n",
    "            boxes, scores, labels = predict_with_grounding_dino(\n",
    "                model=model,\n",
    "                image_path=img_path,\n",
    "                text_prompt=TEXT_PROMPT,\n",
    "                box_threshold=BOX_THRESHOLD,\n",
    "                text_threshold=TEXT_THRESHOLD\n",
    "            )\n",
    "            \n",
    "            # 이미지 정보 가져오기\n",
    "            img_info = image_id_to_info[img_id]\n",
    "            img_width = img_info['width']\n",
    "            img_height = img_info['height']\n",
    "            img_area = img_width * img_height\n",
    "            \n",
    "            # 박스를 COCO 형식으로 변환 및 필터링\n",
    "            coco_boxes = []\n",
    "            coco_scores = []\n",
    "            coco_labels = []\n",
    "            \n",
    "            for i in range(len(boxes)):\n",
    "                x1, y1, x2, y2 = boxes[i]\n",
    "                \n",
    "                # 정규화된 좌표를 픽셀 좌표로 변환\n",
    "                x1 = int(x1 * img_width)\n",
    "                y1 = int(y1 * img_height)\n",
    "                x2 = int(x2 * img_width)\n",
    "                y2 = int(y2 * img_height)\n",
    "                \n",
    "                # 박스 크기 계산\n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "                box_area = w * h\n",
    "                \n",
    "                # 필터링: 너무 작거나 너무 큰 박스 제거\n",
    "                if box_area < MIN_BOX_AREA:\n",
    "                    continue\n",
    "                if box_area > img_area * MAX_BOX_AREA_RATIO:\n",
    "                    continue\n",
    "                \n",
    "                # 이미지 범위 내인지 확인\n",
    "                if x1 < 0 or y1 < 0 or x2 > img_width or y2 > img_height:\n",
    "                    # 클리핑\n",
    "                    x1 = max(0, min(x1, img_width))\n",
    "                    y1 = max(0, min(y1, img_height))\n",
    "                    x2 = max(0, min(x2, img_width))\n",
    "                    y2 = max(0, min(y2, img_height))\n",
    "                    w = x2 - x1\n",
    "                    h = y2 - y1\n",
    "                    \n",
    "                    # 클리핑 후에도 너무 작으면 스킵\n",
    "                    if w * h < MIN_BOX_AREA:\n",
    "                        continue\n",
    "                \n",
    "                # COCO 형식: [x, y, width, height]\n",
    "                coco_box = [x1, y1, w, h]\n",
    "                coco_boxes.append(coco_box)\n",
    "                coco_scores.append(float(scores[i]))\n",
    "                coco_labels.append(int(labels[i]))\n",
    "            \n",
    "            # 결과 저장\n",
    "            result = {\n",
    "                'image_id': img_id,\n",
    "                'file_name': file_name,\n",
    "                'boxes': coco_boxes,\n",
    "                'scores': coco_scores,\n",
    "                'labels': coco_labels\n",
    "            }\n",
    "            all_results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {file_name} 처리 실패: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"✅ 추론 완료: {len(all_results)}개 이미지\")\n",
    "else:\n",
    "    print(\"❌ 모델이 로드되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962be27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 (visualization.py 방식으로 변경)\n",
    "\n",
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "# visualization.py의 COLORS 상수 사용 (RGB 0-255 범위)\n",
    "CLASS_COLORS_RGB = {\n",
    "    0: (255, 0, 0),        # fully-ripe (red)\n",
    "    1: (255, 165, 0),      # semi-ripe (orange) \n",
    "    2: (0, 128, 0),        # unripe (green)\n",
    "}\n",
    "\n",
    "def visualize_predictions(\n",
    "    image_path: str,\n",
    "    predictions: Dict,\n",
    "    ground_truth: Optional[List[Dict]] = None,\n",
    "    save_path: Optional[str] = None,\n",
    "    confidence_threshold: float = 0.3\n",
    "):\n",
    "    \"\"\"예측 결과 시각화 (visualization.py 방식)\"\"\"\n",
    "    # 이미지 로드\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # PIL ImageDraw 사용\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # 폰트 설정\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 16)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # 예측 박스 그리기 (confidence threshold 적용)\n",
    "    for box, score, label in zip(\n",
    "        predictions['boxes'],\n",
    "        predictions['scores'],\n",
    "        predictions['labels']\n",
    "    ):\n",
    "        # Confidence threshold 적용\n",
    "        if score < confidence_threshold:\n",
    "            continue\n",
    "            \n",
    "        x, y, w, h = box\n",
    "        \n",
    "        # 박스 좌표 검증 및 정규화\n",
    "        # w, h가 음수이거나 0인 경우 스킵\n",
    "        if w <= 0 or h <= 0:\n",
    "            continue\n",
    "        \n",
    "        # 좌표를 정수로 변환\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        \n",
    "        # 이미지 범위 내로 클리핑\n",
    "        x1 = max(0, min(x, img_width))\n",
    "        y1 = max(0, min(y, img_height))\n",
    "        x2 = max(0, min(x + w, img_width))\n",
    "        y2 = max(0, min(y + h, img_height))\n",
    "        \n",
    "        # 클리핑 후 유효한 박스인지 확인\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "        \n",
    "        # 박스가 너무 작은 경우 스킵\n",
    "        box_area = (x2 - x1) * (y2 - y1)\n",
    "        img_area = img_width * img_height\n",
    "        if box_area < 100:  # 최소 면적\n",
    "            continue\n",
    "        if box_area > img_area * 0.8:  # 너무 큰 박스 제거\n",
    "            continue\n",
    "        \n",
    "        # 색상 가져오기\n",
    "        color_rgb = CLASS_COLORS_RGB.get(label, (255, 255, 255))\n",
    "        \n",
    "        # 박스 그리기 (visualization.py처럼 width=8)\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color_rgb, width=8)\n",
    "        \n",
    "        # 라벨 텍스트\n",
    "        class_name = CLASS_NAMES[label]\n",
    "        text = f\"{class_name}: {score:.2f}\"\n",
    "        \n",
    "        # 텍스트 배경 그리기\n",
    "        bbox = draw.textbbox((x1, y1 - 20), text, font=font)\n",
    "        draw.rectangle(bbox, fill=color_rgb)\n",
    "        draw.text((x1, y1 - 20), text, fill=\"white\", font=font)\n",
    "    \n",
    "    # GT 박스 그리기 (있는 경우) - 파란색 점선\n",
    "    if ground_truth:\n",
    "        for ann in ground_truth:\n",
    "            x, y, w, h = ann['bbox']\n",
    "            \n",
    "            # GT 박스 좌표 검증 및 정규화\n",
    "            if w <= 0 or h <= 0:\n",
    "                continue\n",
    "            \n",
    "            x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "            \n",
    "            # 이미지 범위 내로 클리핑\n",
    "            x1 = max(0, min(x, img_width))\n",
    "            y1 = max(0, min(y, img_height))\n",
    "            x2 = max(0, min(x + w, img_width))\n",
    "            y2 = max(0, min(y + h, img_height))\n",
    "            \n",
    "            # 유효한 박스인지 확인\n",
    "            if x2 <= x1 or y2 <= y1:\n",
    "                continue\n",
    "            \n",
    "            # GT는 파란색으로 표시\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=\"blue\", width=4)\n",
    "            \n",
    "            category_id = ann['category_id']\n",
    "            category_name = category_id_to_name[category_id]\n",
    "            text = f\"GT: {category_name}\"\n",
    "            \n",
    "            bbox = draw.textbbox((x1, y1 - 20), text, font=font)\n",
    "            draw.rectangle(bbox, fill=\"blue\")\n",
    "            draw.text((x1, y1 - 20), text, fill=\"white\", font=font)\n",
    "    \n",
    "    # 저장 또는 표시\n",
    "    if save_path:\n",
    "        img.save(save_path, quality=95, optimize=False)\n",
    "    else:\n",
    "        img.show()\n",
    "\n",
    "# 몇 개 이미지 시각화\n",
    "if model is not None and len(all_results) > 0:\n",
    "    num_visualize = min(5, len(all_results))\n",
    "    confidence_threshold = 0.3  # 임계값 설정\n",
    "    \n",
    "    for i in range(num_visualize):\n",
    "        result = all_results[i]\n",
    "        img_id = result['image_id']\n",
    "        img_path = os.path.join(test_images_dir, result['file_name'])\n",
    "        \n",
    "        # GT 어노테이션 가져오기\n",
    "        gt_anns = annotations_by_image.get(img_id, [])\n",
    "        \n",
    "        # 예측 결과 준비\n",
    "        pred_dict = {\n",
    "            'boxes': result['boxes'],\n",
    "            'scores': result['scores'],\n",
    "            'labels': result['labels']\n",
    "        }\n",
    "        \n",
    "        # 시각화 저장\n",
    "        save_path = os.path.join(\n",
    "            output_dir, \"visualizations\",\n",
    "            f\"pred_{result['file_name']}\"\n",
    "        )\n",
    "        visualize_predictions(\n",
    "            img_path, \n",
    "            pred_dict, \n",
    "            gt_anns, \n",
    "            save_path,\n",
    "            confidence_threshold=confidence_threshold\n",
    "        )\n",
    "    \n",
    "    print(f\"✅ {num_visualize}개 이미지 시각화 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a2b8be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 5개 이미지 시각화 완료\n"
     ]
    }
   ],
   "source": [
    "# 시각화 (visualization.py 방식으로 변경)\n",
    "\n",
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "# visualization.py의 COLORS 상수 사용 (RGB 0-255 범위)\n",
    "CLASS_COLORS_RGB = {\n",
    "    0: (255, 0, 0),        # fully-ripe (red) - 빨간색\n",
    "    1: (255, 165, 0),      # semi-ripe (orange) - 오렌지색\n",
    "    2: (0, 128, 0),        # unripe (green) - 초록색\n",
    "}\n",
    "\n",
    "def visualize_predictions(\n",
    "    image_path: str,\n",
    "    predictions: Dict,\n",
    "    save_path: Optional[str] = None,\n",
    "    confidence_threshold: float = 0.2\n",
    "):\n",
    "    \"\"\"예측 결과 시각화 (모델 예측만 표시)\"\"\"\n",
    "    # 이미지 로드\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # PIL ImageDraw 사용\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # 폰트 설정\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 16)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # 예측 박스 그리기 (confidence threshold만 적용)\n",
    "    for box, score, label in zip(\n",
    "        predictions['boxes'],\n",
    "        predictions['scores'],\n",
    "        predictions['labels']\n",
    "    ):\n",
    "        # Confidence threshold 적용\n",
    "        if score < confidence_threshold:\n",
    "            continue\n",
    "            \n",
    "        x, y, w, h = box\n",
    "        \n",
    "        # 박스 좌표 정규화 (w, h가 음수인 경우 처리)\n",
    "        if w < 0:\n",
    "            x = x + w\n",
    "            w = abs(w)\n",
    "        if h < 0:\n",
    "            y = y + h\n",
    "            h = abs(h)\n",
    "        \n",
    "        # 좌표를 정수로 변환\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        \n",
    "        # 이미지 범위 내로 클리핑\n",
    "        x1 = max(0, min(x, img_width))\n",
    "        y1 = max(0, min(y, img_height))\n",
    "        x2 = max(0, min(x + w, img_width))\n",
    "        y2 = max(0, min(y + h, img_height))\n",
    "        \n",
    "        # 클리핑 후 유효한 박스인지 확인\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "        \n",
    "        # 색상 가져오기 (클래스별 색상)\n",
    "        # label=0: fully-ripe (빨간색)\n",
    "        # label=1: semi-ripe (오렌지색)\n",
    "        # label=2: unripe (초록색)\n",
    "        color_rgb = CLASS_COLORS_RGB.get(label, (255, 255, 255))\n",
    "        \n",
    "        # 박스 그리기 (visualization.py처럼 width=8)\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color_rgb, width=8)\n",
    "        \n",
    "        # 라벨 텍스트\n",
    "        class_name = CLASS_NAMES[label]\n",
    "        text = f\"{class_name}: {score:.2f}\"\n",
    "        \n",
    "        # 텍스트 배경 그리기\n",
    "        bbox = draw.textbbox((x1, y1 - 20), text, font=font)\n",
    "        draw.rectangle(bbox, fill=color_rgb)\n",
    "        draw.text((x1, y1 - 20), text, fill=\"white\", font=font)\n",
    "    \n",
    "    # 저장 또는 표시\n",
    "    if save_path:\n",
    "        img.save(save_path, quality=95, optimize=False)\n",
    "    else:\n",
    "        img.show()\n",
    "\n",
    "# 몇 개 이미지 시각화\n",
    "if model is not None and len(all_results) > 0:\n",
    "    num_visualize = min(5, len(all_results))\n",
    "    confidence_threshold = 0.2  # 임계값 설정\n",
    "    \n",
    "    for i in range(num_visualize):\n",
    "        result = all_results[i]\n",
    "        img_id = result['image_id']\n",
    "        img_path = os.path.join(test_images_dir, result['file_name'])\n",
    "        \n",
    "        # 예측 결과 준비 (모델이 예측한 결과만 사용)\n",
    "        pred_dict = {\n",
    "            'boxes': result['boxes'],      # 모델 예측 박스\n",
    "            'scores': result['scores'],     # 모델 예측 점수\n",
    "            'labels': result['labels']      # 모델 예측 라벨\n",
    "        }\n",
    "        \n",
    "        # 시각화 저장\n",
    "        save_path = os.path.join(\n",
    "            output_dir, \"visualizations\",\n",
    "            f\"pred_{result['file_name']}\"\n",
    "        )\n",
    "        visualize_predictions(\n",
    "            img_path, \n",
    "            pred_dict, \n",
    "            save_path,\n",
    "            confidence_threshold=confidence_threshold\n",
    "        )\n",
    "    \n",
    "    print(f\"✅ {num_visualize}개 이미지 시각화 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO 메트릭 계산\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# 예측 결과를 COCO 형식으로 변환\n",
    "coco_predictions = []\n",
    "for result in all_results:\n",
    "    img_id = result['image_id']\n",
    "    for box, score, label in zip(\n",
    "        result['boxes'],\n",
    "        result['scores'],\n",
    "        result['labels']\n",
    "    ):\n",
    "        # COCO 카테고리 ID로 변환\n",
    "        class_name = CLASS_NAMES[label]\n",
    "        category_id = category_name_to_id[class_name]\n",
    "        \n",
    "        coco_pred = {\n",
    "            'image_id': img_id,\n",
    "            'category_id': category_id,\n",
    "            'bbox': box,\n",
    "            'score': score\n",
    "        }\n",
    "        coco_predictions.append(coco_pred)\n",
    "\n",
    "# COCO 평가 수행\n",
    "if len(coco_predictions) > 0:\n",
    "    # 예측 결과를 JSON 파일로 저장\n",
    "    pred_file = os.path.join(output_dir, \"predictions\", \"predictions.json\")\n",
    "    with open(pred_file, 'w') as f:\n",
    "        json.dump(coco_predictions, f)\n",
    "    \n",
    "    # COCO annotation 파일에 'info' 키가 없으면 추가\n",
    "    with open(test_ann_file, 'r') as f:\n",
    "        coco_gt_data = json.load(f)\n",
    "    \n",
    "    # 'info' 키가 없으면 추가\n",
    "    if 'info' not in coco_gt_data:\n",
    "        coco_gt_data['info'] = {\n",
    "            'description': 'Tomato Detection Dataset',\n",
    "            'version': '1.0',\n",
    "            'year': 2024\n",
    "        }\n",
    "        # 임시 파일로 저장\n",
    "        temp_ann_file = os.path.join(output_dir, \"temp_annotations.json\")\n",
    "        with open(temp_ann_file, 'w') as f:\n",
    "            json.dump(coco_gt_data, f)\n",
    "        test_ann_file = temp_ann_file\n",
    "    \n",
    "    # COCO 객체 생성\n",
    "    coco_gt = COCO(test_ann_file)\n",
    "    coco_dt = coco_gt.loadRes(pred_file)\n",
    "    \n",
    "    # 평가 실행\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    \n",
    "    # 결과 저장\n",
    "    metrics = {\n",
    "        'mAP': float(coco_eval.stats[0]),\n",
    "        'mAP50': float(coco_eval.stats[1]),\n",
    "        'mAP75': float(coco_eval.stats[2]),\n",
    "        'mAP_small': float(coco_eval.stats[3]),\n",
    "        'mAP_medium': float(coco_eval.stats[4]),\n",
    "        'mAP_large': float(coco_eval.stats[5]),\n",
    "        'mAR_1': float(coco_eval.stats[6]),\n",
    "        'mAR_10': float(coco_eval.stats[7]),\n",
    "        'mAR_100': float(coco_eval.stats[8]),\n",
    "        'mAR_small': float(coco_eval.stats[9]),\n",
    "        'mAR_medium': float(coco_eval.stats[10]),\n",
    "        'mAR_large': float(coco_eval.stats[11]),\n",
    "    }\n",
    "    \n",
    "    metrics_file = os.path.join(output_dir, \"metrics.json\")\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    \n",
    "    print(\"\\n✅ 평가 완료\")\n",
    "    print(f\"mAP: {metrics['mAP']:.4f}\")\n",
    "    print(f\"mAP50: {metrics['mAP50']:.4f}\")\n",
    "    print(f\"mAP75: {metrics['mAP75']:.4f}\")\n",
    "else:\n",
    "    print(\"❌ 평가할 예측 결과가 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 요약 출력\n",
    "if model is not None:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Grounding DINO 추론 결과 요약\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"처리된 이미지 수: {len(all_results)}\")\n",
    "    print(f\"총 예측 박스 수: {sum(len(r['boxes']) for r in all_results)}\")\n",
    "    \n",
    "    # 클래스별 예측 수\n",
    "    class_counts = {name: 0 for name in CLASS_NAMES}\n",
    "    for result in all_results:\n",
    "        for label in result['labels']:\n",
    "            class_counts[CLASS_NAMES[label]] += 1\n",
    "    \n",
    "    print(\"\\n클래스별 예측 수:\")\n",
    "    for class_name, count in class_counts.items():\n",
    "        print(f\"  {class_name}: {count}\")\n",
    "    \n",
    "    print(f\"\\n결과 저장 위치: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e6862",
   "metadata": {},
   "source": [
    "### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e084f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from groundingdino.util.inference import load_model\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2778f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 collate_fn: 가변 길이 데이터 처리\n",
    "def collate_fn(batch):\n",
    "    \"\"\"가변 길이 박스와 라벨을 처리하는 collate 함수\"\"\"\n",
    "    images = []\n",
    "    text_prompts = []\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    image_ids = []\n",
    "    \n",
    "    for item in batch:\n",
    "        images.append(item['image'])\n",
    "        text_prompts.append(item['text_prompt'])\n",
    "        boxes.append(torch.tensor(item['boxes'], dtype=torch.float32))\n",
    "        labels.append(torch.tensor(item['labels'], dtype=torch.long))\n",
    "        image_ids.append(item['image_id'])\n",
    "    \n",
    "    # 이미지들을 배치로 묶기\n",
    "    images = torch.stack(images)\n",
    "    \n",
    "    return {\n",
    "        'image': images,\n",
    "        'text_prompt': text_prompts,  # 리스트로 유지 (각각 다른 프롬프트일 수 있음)\n",
    "        'boxes': boxes,  # 리스트로 유지 (각 이미지마다 박스 개수 다름)\n",
    "        'labels': labels,  # 리스트로 유지\n",
    "        'image_id': image_ids\n",
    "    }\n",
    "# Grounding DINO의 inference에서 사용하는 transforms 확인\n",
    "# load_image 함수를 참고하여 동일한 전처리 사용\n",
    "def create_grounding_dino_transform():\n",
    "    \"\"\"Grounding DINO와 동일한 이미지 전처리\"\"\"\n",
    "    return T.Compose([\n",
    "        T.Resize([800], max_size=1333),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c39acdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class GroundingDINODataset(Dataset):\n",
    "    def __init__(self, ann_file, images_dir, transform=None):\n",
    "        with open(ann_file, 'r') as f:\n",
    "            self.coco_data = json.load(f)\n",
    "        \n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 이미지 ID와 파일명 매핑\n",
    "        self.image_id_to_file = {img['id']: img['file_name'] for img in self.coco_data['images']}\n",
    "        self.image_ids = list(self.image_id_to_file.keys())\n",
    "        \n",
    "        # 어노테이션을 이미지 ID별로 그룹화\n",
    "        self.annotations_by_image = {}\n",
    "        for ann in self.coco_data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in self.annotations_by_image:\n",
    "                self.annotations_by_image[img_id] = []\n",
    "            self.annotations_by_image[img_id].append(ann)\n",
    "        \n",
    "        # 카테고리 매핑\n",
    "        self.category_id_to_name = {cat['id']: cat['name'] for cat in self.coco_data['categories']}\n",
    "        self.category_name_to_id = {cat['name']: cat['id'] for cat in self.coco_data['categories']}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx]\n",
    "        file_name = self.image_id_to_file[img_id]\n",
    "        img_path = os.path.join(self.images_dir, file_name)\n",
    "        \n",
    "        # 이미지 로드\n",
    "        from PIL import Image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # 어노테이션 가져오기\n",
    "        anns = self.annotations_by_image.get(img_id, [])\n",
    "        \n",
    "        # 텍스트 프롬프트 생성\n",
    "        text_prompt = \". \".join([f\"{name} tomato\" for name in CLASS_NAMES]) + \".\"\n",
    "        \n",
    "        # 변환 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # 타겟 준비 (bbox, labels)\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in anns:\n",
    "            boxes.append(ann['bbox'])  # [x, y, w, h]\n",
    "            category_id = ann['category_id']\n",
    "            category_name = self.category_id_to_name[category_id]\n",
    "            label = CLASS_NAMES.index(category_name)\n",
    "            labels.append(label)\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'text_prompt': text_prompt,\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': img_id\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cbe4769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 193\n",
      "Val samples: 54\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 및 데이터로더 생성\n",
    "train_ann_file = get_project_path(\"data\", \"TomatOD_COCO_3\", \"train\", \"custom_train.json\")\n",
    "train_images_dir = get_project_path(\"data\", \"TomatOD_COCO_3\", \"train\", \"images\")\n",
    "val_ann_file = get_project_path(\"data\", \"TomatOD_COCO_3\", \"val\", \"custom_val.json\")\n",
    "val_images_dir = get_project_path(\"data\", \"TomatOD_COCO_3\", \"val\", \"images\")\n",
    "\n",
    "# 변환 정의\n",
    "transform = create_grounding_dino_transform()\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = GroundingDINODataset(train_ann_file, train_images_dir, transform=transform)\n",
    "val_dataset = GroundingDINODataset(val_ann_file, val_images_dir, transform=transform)\n",
    "\n",
    "# DataLoader에 collate_fn 추가\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=2, \n",
    "    shuffle=True, \n",
    "    num_workers=0,  # 멀티프로세싱 문제 방지를 위해 0으로 설정\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=2, \n",
    "    shuffle=False, \n",
    "    num_workers=0,  # 멀티프로세싱 문제 방지를 위해 0으로 설정\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d0480ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델 설정 (학습 모드)\n",
    "model.train()\n",
    "\n",
    "# 옵티마이저 및 스케줄러 설정\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b33db62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:25<00:00,  3.77it/s]\n",
      "Validation: 100%|██████████| 27/27 [00:06<00:00,  4.00it/s]\n",
      "/home/hyeonjin/tomato-detection-agentic/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Val Loss: 0.0000\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:27<00:00,  3.55it/s]\n",
      "Validation: 100%|██████████| 27/27 [00:06<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Val Loss: 0.0000\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:26<00:00,  3.64it/s]\n",
      "Validation: 100%|██████████| 27/27 [00:07<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Val Loss: 0.0000\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
      "Validation: 100%|██████████| 27/27 [00:07<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Val Loss: 0.0000\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:24<00:00,  3.96it/s]\n",
      "Validation: 100%|██████████| 27/27 [00:09<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Val Loss: 0.0000\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:24<00:00,  3.96it/s]\n",
      "Validation: 100%|██████████| 27/27 [00:08<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Val Loss: 0.0000\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:25<00:00,  3.77it/s]\n",
      "Validation: 100%|██████████| 27/27 [00:08<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Val Loss: 0.0000\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:24<00:00,  3.93it/s]\n",
      "Validation: 100%|██████████| 27/27 [00:08<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Val Loss: 0.0000\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:24<00:00,  3.95it/s]\n",
      "Validation: 100%|██████████| 27/27 [00:07<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Val Loss: 0.0000\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:25<00:00,  3.80it/s]\n",
      "Validation: 100%|██████████| 27/27 [00:06<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0000, Val Loss: 0.0000\n",
      "✅ 파인튜닝된 모델 저장: /home/hyeonjin/tomato-detection-agentic/weights/groundingdino_finetuned.pth\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "num_epochs = 10\n",
    "device = 'cuda'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        # 배치 데이터 처리\n",
    "        images = batch['image'].to(device)\n",
    "        text_prompts = batch['text_prompt']\n",
    "        boxes = batch['boxes']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Grounding DINO의 forward는 복잡하므로 실제 구현 필요\n",
    "        # 여기서는 예시 구조만 제공\n",
    "        # outputs = model(images, captions=text_prompts)\n",
    "        # loss = compute_loss(outputs, boxes, labels)\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        \n",
    "        # train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            # Validation 로직\n",
    "            pass\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(f\"Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "# 모델 저장\n",
    "save_path = get_project_path(\"weights\", \"groundingdino_finetuned.pth\")\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"✅ 파인튜닝된 모델 저장: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e0fb8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config path: /home/hyeonjin/tomato-detection-agentic/configs/gdino/gdino_3class.py\n",
      "Original weights path: /home/hyeonjin/tomato-detection-agentic/weights/groundingdino_swint_ogc.pth\n",
      "Finetuned weights path: /home/hyeonjin/tomato-detection-agentic/weights/groundingdino_finetuned.pth\n",
      "final text_encoder_type: bert-base-uncased\n",
      "파인튜닝된 가중치를 로드합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_598929/1068734908.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  finetuned_state_dict = torch.load(FINETUNED_WEIGHTS_PATH, map_location='cuda')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 파인튜닝된 가중치 적용 완료\n",
      "✅ Grounding DINO 모델 로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정 (파인튜닝된 가중치 사용)\n",
    "PROJECT_ROOT = find_project_root()\n",
    "CONFIG_PATH = get_project_path(\"configs\", \"gdino\", \"gdino_3class.py\")\n",
    "ORIGINAL_WEIGHTS_PATH = get_project_path(\"weights\", \"groundingdino_swint_ogc.pth\")  # 원본 가중치\n",
    "FINETUNED_WEIGHTS_PATH = get_project_path(\"weights\", \"groundingdino_finetuned.pth\")  # 파인튜닝된 가중치\n",
    "\n",
    "print(f\"Config path: {CONFIG_PATH}\")\n",
    "print(f\"Original weights path: {ORIGINAL_WEIGHTS_PATH}\")\n",
    "print(f\"Finetuned weights path: {FINETUNED_WEIGHTS_PATH}\")\n",
    "\n",
    "# 모델 로드 (원본 가중치로 먼저 로드)\n",
    "if GROUNDING_DINO_AVAILABLE:\n",
    "    try:\n",
    "        # 1단계: 원본 가중치로 모델 구조 로드\n",
    "        model = load_model(CONFIG_PATH, ORIGINAL_WEIGHTS_PATH, device='cuda')\n",
    "        \n",
    "        # 2단계: 파인튜닝된 state_dict 로드 및 적용\n",
    "        if os.path.exists(FINETUNED_WEIGHTS_PATH):\n",
    "            print(\"파인튜닝된 가중치를 로드합니다...\")\n",
    "            finetuned_state_dict = torch.load(FINETUNED_WEIGHTS_PATH, map_location='cuda')\n",
    "            model.load_state_dict(finetuned_state_dict)\n",
    "            print(\"✅ 파인튜닝된 가중치 적용 완료\")\n",
    "        else:\n",
    "            print(\"⚠️ 파인튜닝된 가중치 파일을 찾을 수 없습니다. 원본 가중치를 사용합니다.\")\n",
    "        \n",
    "        model.eval()\n",
    "        print(\"✅ Grounding DINO 모델 로드 완료\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 모델 로드 실패: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"수동으로 모델을 다운로드하거나 경로를 확인하세요.\")\n",
    "        model = None\n",
    "else:\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f76a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 모델이 로드되지 않았습니다.\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 엔지니어링: 클래스별 개별 추론\n",
    "\n",
    "# 클래스 정의\n",
    "CLASS_NAMES = ['fully-ripe', 'semi-ripe', 'unripe']\n",
    "CLASS_COLORS = ['#D0021B', '#F8E71C', '#7ED321']  # 빨강, 노랑, 초록\n",
    "\n",
    "def predict_with_grounding_dino_per_class(\n",
    "    model,\n",
    "    image_path: str,\n",
    "    class_name: str,\n",
    "    box_threshold: float = 0.3,\n",
    "    text_threshold: float = 0.25\n",
    ") -> Tuple[np.ndarray, np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    단일 클래스에 대해 Grounding DINO로 예측 수행\n",
    "    \n",
    "    Returns:\n",
    "        boxes: (N, 4) numpy array [x1, y1, x2, y2] (정규화된 좌표)\n",
    "        scores: (N,) numpy array\n",
    "        label: 클래스 인덱스\n",
    "    \"\"\"\n",
    "    # 단일 클래스 프롬프트\n",
    "    text_prompt = f\"{class_name} tomato.\"\n",
    "    \n",
    "    # 이미지 로드 및 전처리\n",
    "    image_source, image = load_image(image_path)\n",
    "    \n",
    "    # 예측 수행\n",
    "    boxes, logits, phrases = predict(\n",
    "        model=model,\n",
    "        image=image,\n",
    "        caption=text_prompt,\n",
    "        box_threshold=box_threshold,\n",
    "        text_threshold=text_threshold\n",
    "    )\n",
    "    \n",
    "    # 클래스 인덱스 찾기\n",
    "    class_idx = CLASS_NAMES.index(class_name)\n",
    "    \n",
    "    # 모든 박스에 동일한 라벨 할당\n",
    "    labels = np.full(len(boxes), class_idx)\n",
    "    \n",
    "    return boxes, logits, labels\n",
    "\n",
    "# 배치 추론 실행 (클래스별 개별 추론)\n",
    "all_results = []\n",
    "\n",
    "BOX_THRESHOLD = 0.3\n",
    "TEXT_THRESHOLD = 0.25\n",
    "MIN_BOX_AREA = 100\n",
    "MAX_BOX_AREA_RATIO = 0.8\n",
    "\n",
    "if model is not None:\n",
    "    for img_id, img_path, file_name in tqdm(test_image_files, desc=\"추론 중\"):\n",
    "        try:\n",
    "            # 이미지 정보 가져오기\n",
    "            img_info = image_id_to_info[img_id]\n",
    "            img_width = img_info['width']\n",
    "            img_height = img_info['height']\n",
    "            img_area = img_width * img_height\n",
    "            \n",
    "            # 모든 클래스에 대해 개별 추론\n",
    "            all_boxes = []\n",
    "            all_scores = []\n",
    "            all_labels = []\n",
    "            \n",
    "            for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "                # 각 클래스별로 개별 추론\n",
    "                boxes, scores, labels = predict_with_grounding_dino_per_class(\n",
    "                    model=model,\n",
    "                    image_path=img_path,\n",
    "                    class_name=class_name,\n",
    "                    box_threshold=BOX_THRESHOLD,\n",
    "                    text_threshold=TEXT_THRESHOLD\n",
    "                )\n",
    "                \n",
    "                # 박스를 COCO 형식으로 변환 및 필터링\n",
    "                for i in range(len(boxes)):\n",
    "                    x1, y1, x2, y2 = boxes[i]\n",
    "                    \n",
    "                    # 정규화된 좌표를 픽셀 좌표로 변환\n",
    "                    x1 = int(x1 * img_width)\n",
    "                    y1 = int(y1 * img_height)\n",
    "                    x2 = int(x2 * img_width)\n",
    "                    y2 = int(y2 * img_height)\n",
    "                    \n",
    "                    # 박스 크기 계산\n",
    "                    w = x2 - x1\n",
    "                    h = y2 - y1\n",
    "                    box_area = w * h\n",
    "                    \n",
    "                    # 필터링\n",
    "                    if box_area < MIN_BOX_AREA:\n",
    "                        continue\n",
    "                    if box_area > img_area * MAX_BOX_AREA_RATIO:\n",
    "                        continue\n",
    "                    \n",
    "                    # 이미지 범위 내인지 확인 및 클리핑\n",
    "                    if x1 < 0 or y1 < 0 or x2 > img_width or y2 > img_height:\n",
    "                        x1 = max(0, min(x1, img_width))\n",
    "                        y1 = max(0, min(y1, img_height))\n",
    "                        x2 = max(0, min(x2, img_width))\n",
    "                        y2 = max(0, min(y2, img_height))\n",
    "                        w = x2 - x1\n",
    "                        h = y2 - y1\n",
    "                        if w * h < MIN_BOX_AREA:\n",
    "                            continue\n",
    "                    \n",
    "                    # COCO 형식: [x, y, width, height]\n",
    "                    coco_box = [x1, y1, w, h]\n",
    "                    all_boxes.append(coco_box)\n",
    "                    all_scores.append(float(scores[i]))\n",
    "                    all_labels.append(int(labels[i]))\n",
    "            \n",
    "            # 결과 저장\n",
    "            result = {\n",
    "                'image_id': img_id,\n",
    "                'file_name': file_name,\n",
    "                'boxes': all_boxes,\n",
    "                'scores': all_scores,\n",
    "                'labels': all_labels\n",
    "            }\n",
    "            all_results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {file_name} 처리 실패: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"✅ 추론 완료: {len(all_results)}개 이미지\")\n",
    "else:\n",
    "    print(\"❌ 모델이 로드되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c7ad4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# visualization.py의 COLORS 상수 사용 (RGB 0-255 범위)\u001b[39;00m\n\u001b[32m      6\u001b[39m CLASS_COLORS_RGB = {\n\u001b[32m      7\u001b[39m     \u001b[32m0\u001b[39m: (\u001b[32m255\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m),        \u001b[38;5;66;03m# fully-ripe (red) - 빨간색\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[32m1\u001b[39m: (\u001b[32m255\u001b[39m, \u001b[32m165\u001b[39m, \u001b[32m0\u001b[39m),      \u001b[38;5;66;03m# semi-ripe (orange) - 오렌지색\u001b[39;00m\n\u001b[32m      9\u001b[39m     \u001b[32m2\u001b[39m: (\u001b[32m0\u001b[39m, \u001b[32m128\u001b[39m, \u001b[32m0\u001b[39m),        \u001b[38;5;66;03m# unripe (green) - 초록색\u001b[39;00m\n\u001b[32m     10\u001b[39m }\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisualize_predictions\u001b[39m(\n\u001b[32m     13\u001b[39m     image_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     predictions: \u001b[43mDict\u001b[49m,\n\u001b[32m     15\u001b[39m     save_path: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     16\u001b[39m     confidence_threshold: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.2\u001b[39m\n\u001b[32m     17\u001b[39m ):\n\u001b[32m     18\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"예측 결과 시각화 (모델 예측만 표시)\"\"\"\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# 이미지 로드\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'Dict' is not defined"
     ]
    }
   ],
   "source": [
    "# 시각화 (visualization.py 방식으로 변경)\n",
    "\n",
    "from PIL import ImageDraw, ImageFont\n",
    "\n",
    "# visualization.py의 COLORS 상수 사용 (RGB 0-255 범위)\n",
    "CLASS_COLORS_RGB = {\n",
    "    0: (255, 0, 0),        # fully-ripe (red) - 빨간색\n",
    "    1: (255, 165, 0),      # semi-ripe (orange) - 오렌지색\n",
    "    2: (0, 128, 0),        # unripe (green) - 초록색\n",
    "}\n",
    "\n",
    "def visualize_predictions(\n",
    "    image_path: str,\n",
    "    predictions: Dict,\n",
    "    save_path: Optional[str] = None,\n",
    "    confidence_threshold: float = 0.2\n",
    "):\n",
    "    \"\"\"예측 결과 시각화 (모델 예측만 표시)\"\"\"\n",
    "    # 이미지 로드\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # PIL ImageDraw 사용\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # 폰트 설정\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 16)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # 예측 박스 그리기 (confidence threshold만 적용)\n",
    "    for box, score, label in zip(\n",
    "        predictions['boxes'],\n",
    "        predictions['scores'],\n",
    "        predictions['labels']\n",
    "    ):\n",
    "        # Confidence threshold 적용\n",
    "        if score < confidence_threshold:\n",
    "            continue\n",
    "            \n",
    "        x, y, w, h = box\n",
    "        \n",
    "        # 박스 좌표 정규화 (w, h가 음수인 경우 처리)\n",
    "        if w < 0:\n",
    "            x = x + w\n",
    "            w = abs(w)\n",
    "        if h < 0:\n",
    "            y = y + h\n",
    "            h = abs(h)\n",
    "        \n",
    "        # 좌표를 정수로 변환\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        \n",
    "        # 이미지 범위 내로 클리핑\n",
    "        x1 = max(0, min(x, img_width))\n",
    "        y1 = max(0, min(y, img_height))\n",
    "        x2 = max(0, min(x + w, img_width))\n",
    "        y2 = max(0, min(y + h, img_height))\n",
    "        \n",
    "        # 클리핑 후 유효한 박스인지 확인\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "        \n",
    "        # 색상 가져오기 (클래스별 색상)\n",
    "        # label=0: fully-ripe (빨간색)\n",
    "        # label=1: semi-ripe (오렌지색)\n",
    "        # label=2: unripe (초록색)\n",
    "        color_rgb = CLASS_COLORS_RGB.get(label, (255, 255, 255))\n",
    "        \n",
    "        # 박스 그리기 (visualization.py처럼 width=8)\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color_rgb, width=8)\n",
    "        \n",
    "        # 라벨 텍스트\n",
    "        class_name = CLASS_NAMES[label]\n",
    "        text = f\"{class_name}: {score:.2f}\"\n",
    "        \n",
    "        # 텍스트 배경 그리기\n",
    "        bbox = draw.textbbox((x1, y1 - 20), text, font=font)\n",
    "        draw.rectangle(bbox, fill=color_rgb)\n",
    "        draw.text((x1, y1 - 20), text, fill=\"white\", font=font)\n",
    "    \n",
    "    # 저장 또는 표시\n",
    "    if save_path:\n",
    "        img.save(save_path, quality=95, optimize=False)\n",
    "    else:\n",
    "        img.show()\n",
    "\n",
    "# 몇 개 이미지 시각화\n",
    "if model is not None and len(all_results) > 0:\n",
    "    num_visualize = 30\n",
    "    confidence_threshold = 0.2  # 임계값 설정\n",
    "    \n",
    "    for i in range(num_visualize):\n",
    "        result = all_results[i]\n",
    "        img_id = result['image_id']\n",
    "        img_path = os.path.join(test_images_dir, result['file_name'])\n",
    "        \n",
    "        # 예측 결과 준비 (모델이 예측한 결과만 사용)\n",
    "        pred_dict = {\n",
    "            'boxes': result['boxes'],      # 모델 예측 박스\n",
    "            'scores': result['scores'],     # 모델 예측 점수\n",
    "            'labels': result['labels']      # 모델 예측 라벨\n",
    "        }\n",
    "        \n",
    "        # 시각화 저장\n",
    "        save_path = os.path.join(\n",
    "            output_dir, \"visualizations\",\n",
    "            f\"pred_{result['file_name']}\"\n",
    "        )\n",
    "        visualize_predictions(\n",
    "            img_path, \n",
    "            pred_dict, \n",
    "            save_path,\n",
    "            confidence_threshold=confidence_threshold\n",
    "        )\n",
    "    \n",
    "    print(f\"✅ {num_visualize}개 이미지 시각화 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 (tomato-detection-agentic)",
   "language": "python",
   "name": "tomato-detection-agentic"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}